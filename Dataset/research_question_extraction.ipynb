{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from heapq import nlargest\n",
        "import openai\n",
        "import torch\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "with open('data_set_v1.0/author_json.json', 'r',encoding='utf-8') as f:\n",
        "    authors = json.load(f)\n",
        "print(len(authors))\n",
        "\n",
        "with open('data_set_v1.0/paper_json.json', 'r',encoding='utf-8') as f:\n",
        "    papers = json.load(f)\n",
        "print(len(papers))\n",
        "# sampled papers to 500 \n",
        "count = 0\n",
        "max_paper = 100\n",
        "author_paper_count = []\n",
        "paper_author_count = []\n",
        "papers_sampled = {}\n",
        "authors_sampled = {}\n",
        "for i in papers:\n",
        "    if count < 100:\n",
        "        flag = True\n",
        "        for author in papers[i][\"authors\"]:\n",
        "            if len(authors[author][\"papers\"])<5:\n",
        "                flag = False\n",
        "        if flag and len(papers[i][\"authors\"]) > 1:\n",
        "            paper_author_count.append(len(papers[i][\"authors\"]))\n",
        "            papers_sampled[i] = papers[i]\n",
        "            papers_sampled[i][\"author_history\"] = {}\n",
        "            \n",
        "            for author in papers[i][\"authors\"]:\n",
        "                papers_sampled[i][\"author_history\"][author] = {}\n",
        "                papers_sampled[i][\"author_history\"][author][\"authors_history_text\"] = [papers[i][\"abstract\"]]\n",
        "                papers_sampled[i][\"author_history\"][author][\"authors_history_dict\"] = [{\"Abstract\":\"\",\"Title\":\"\"}]\n",
        "                paper_count_tmp = 0\n",
        "                for paper_tmp in authors[author][\"papers\"]:\n",
        "                    if paper_count_tmp < max_paper and paper_tmp[\"title\"] != papers[i][\"title\"]:\n",
        "                        papers_sampled[i][\"author_history\"][author][\"authors_history_text\"].append(\"Abstract: \"+paper_tmp[\"abstract\"]+\"\\nTitle: \"+paper_tmp[\"title\"])\n",
        "                        papers_sampled[i][\"author_history\"][author][\"authors_history_dict\"].append({\"Abstract\":paper_tmp[\"abstract\"],\"Title\":paper_tmp[\"title\"]})\n",
        "                        paper_count_tmp = paper_count_tmp + 1\n",
        "                author_paper_count.append(len(authors[author][\"papers\"]))\n",
        "                authors_sampled[author] = authors[author]\n",
        "            count = count + 1\n",
        "print(\"papers count after sampled: \",len(papers_sampled))\n",
        "print(\"authors count after sampled: \",len(authors_sampled))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "7931\n3275\npapers count after sampled:  100\nauthors count after sampled:  243\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1695472288052
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from heapq import nlargest\n",
        "import openai\n",
        "import torch\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import pandas as pd\n",
        "\n",
        "error_list=[]\n",
        "i = 0\n",
        "openai.api_key = \"31b8638c9eea48709a596501490f9e88\"\n",
        "openai.api_base = \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"\n",
        "openai.api_type = 'azure'\n",
        "openai.api_version = '2023-05-15' # this may change in the future\n",
        "key_bundles = [\n",
        "    ('31b8638c9eea48709a596501490f9e88', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('31b8638c9eea48709a596501490f9e88', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('31b8638c9eea48709a596501490f9e88', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\")\n",
        "]\n",
        "    # prompt_construction v1.6\n",
        "def construct_prompt_cot_agg(paper):\n",
        "\n",
        "    prompt_str = \"\"\n",
        "    prompt_str = prompt_str + \"Assuming youâ€™re the leading author of the following research paper, which contains title, abstract and a snippet of introduction. Please extract the research questions from it:\\n\"\n",
        "    prompt_str = prompt_str + \"Title:\" + paper[\"title\"] + \"\\n\"\n",
        "    prompt_str = prompt_str + \"Abstract:\" + paper[\"abstract\"] + \"\\n\"\n",
        "\n",
        "    prompt_str = prompt_str + \"Please extract top 3 research questions from the above information and make it a list\"+\"\\n\"\n",
        "    prompt_str = prompt_str + \"Research question: \"\n",
        "\n",
        "    return prompt_str\n",
        "\n",
        "\n",
        "def run_openai(prompt,key_bundles,i,indice):\n",
        "    my_dict = {}\n",
        "    my_dict[\"role\"] = \"user\"\n",
        "    my_dict[\"content\"] = prompt\n",
        "    l = []\n",
        "    l.append(my_dict)\n",
        "    result = \"\"\n",
        "    try:\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        response = openai.ChatCompletion.create(engine=\"gpt-4\", messages=l, temperature=0.0,request_timeout=30)\n",
        "        result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "        # print(indice+\"\\t\"+result+\"\\n\")\n",
        "        return result\n",
        "    except openai.error.Timeout:\n",
        "        i = i+1\n",
        "        print(\"Timeout\",indice)\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(engine=\"gpt-4\", messages=l, temperature=0.0,request_timeout=30)\n",
        "            result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "            # print(indice+\"\\t\"+result+\"\\n\")\n",
        "            return result\n",
        "        except openai.error.Timeout:\n",
        "            i = i+1\n",
        "            print(\"Timeout\",indice)\n",
        "            key_bundle = key_bundles[i%3]\n",
        "            openai.api_key, openai.api_base = key_bundle\n",
        "            try:\n",
        "                response = openai.ChatCompletion.create(engine=\"gpt-4\", messages=l, temperature=0.0,request_timeout=30)\n",
        "                result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "                # print(indice+\"\\t\"+result+\"\\n\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {str(e)}\")\n",
        "                error_list.append(i)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            error_list.append(i)\n",
        "        #print(result)\n",
        "    except openai.error.InvalidRequestError:\n",
        "        print(\"InvalidRequestError\",indice)\n",
        "        error_list.append(i)\n",
        "        #print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        error_list.append(i)\n",
        "    return result\n",
        "\n",
        "id2rq = {}\n",
        "with open(\"naive_method_v1.0/paper_research_questions.tsv\", \"wb\", buffering=0) as out_file:\n",
        "    for indice,paperId in enumerate(papers_sampled):\n",
        "        prompt = construct_prompt_cot_agg(papers_sampled[paperId])\n",
        "        # print(prompt)\n",
        "        # break\n",
        "        result = run_openai(prompt,key_bundles,i,indice)\n",
        "        print(indice, result)\n",
        "        id2rq[paperId] = result\n",
        "        write_str = bytes(str(paperId)+\"\\t\"+result+\"\\n\", 'utf-8')\n",
        "        out_file.write(write_str)\n",
        "        "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0 1. How can model-based approaches improve the daily practice of software professionals through Model-Driven Software Engineering (MDSE) or Model-Driven Engineering (MDE)? 2. What are the basic principles and techniques of MDSE that can be quickly understood and applied for immediate benefit? 3. How can the integration of MDSE in existing development processes be effectively achieved, and what are the technical aspects of MDSE, including the building of a domain-specific modeling language and the description of Model-to-Text and Model-to-Model transformations?\n1 1. How can a systematic mapping study be effectively conducted in the field of software engineering? 2. What are the key differences between systematic maps and systematic reviews in software engineering, and how can these differences guide the choice between them? 3. What are the guidelines for conducting systematic maps in software engineering based on the comparison with systematic reviews?\n2 1. What are the main issues and vulnerabilities associated with smart contract programming and other applications running on blockchains? 2. How could recognized best practices in software engineering mitigate the detrimental software misbehavior observed in the case of the Parity wallet application? 3. What specificities of Smart Contract software development make existing software engineering approaches insufficient, and what should be included in the definition of a specific Blockchain Software Engineering discipline to address these?\n3 1. What are the consistencies and inconsistencies in the research methods and terminologies used in Software Engineering (SE) research? 2. How does the ABC framework, which aims for generalizability over Actors and precise measurement of their Behavior in a realistic Context, apply to the research strategies in SE, particularly in the domains of global software engineering and requirements engineering? 3. In what ways can the ABC framework advance SE research and overcome the limitations inherent in the current research strategies?\n4 1. How effective and reliable are the three sentiment analysis tools specifically customized for software engineering in identifying developers' emotions? 2. What are the limitations of using off-the-shelf sentiment analysis tools in the software engineering domain? 3. What are the open challenges in sentiment analysis for software engineering, as identified from a qualitative analysis of misclassified texts?\n5 1. What are the key challenges in the accuracy of systems built using Machine Learning and AI models? 2. How can the testing of Machine Learning and AI-based systems be effectively conducted? 3. What are the practical implications and industrial applications of AI, and how can the rift between the Machine Learning and Software Engineering communities be bridged?\n6 1. What are the common aspects and trends in App Store Analysis that have been explored in previous research? 2. How can the findings from App Store Analysis be utilized for requirements engineering, release planning, software design, security and testing? 3. What are the potential directions for future research in App Store Analysis to address open problems and challenges?\n7 1. What are the variants of Grounded Theory (GT) and what constitutes the core set of GT practices? 2. How is Grounded Theory being utilized in the field of software engineering and what is the quality of these applications? 3. What guidelines can be established to improve the quality of conducting and reporting GT studies in software engineering, especially considering the current lack of guidelines for the reporting process?\n8 1. What are the main difficulties causing inaccuracies in automated sentiment analysis tools used in software engineering? 2. How can these identified difficulties be addressed in the development of a new tool, SentiStrength-SE, for improved sentiment analysis in the software engineering domain? 3. How does the performance of SentiStrength-SE, in terms of precision and recall, compare to existing state-of-the-art sentiment analysis tools in the software engineering field?\n9 1. How can the lexical gap between natural language search queries and code-based retrieved documents in software engineering be effectively bridged? 2. Can projecting natural language statements and code snippets as meaning vectors in a shared representation space improve information retrieval in software engineering? 3. How effective are the learned vector space embeddings in improving previously explored bug localization tasks and linking API documents to computer programming questions?\n10 1. How can model-based approaches improve the daily practice of software professionals and increase efficiency and effectiveness in software development? 2. What are the basic principles and techniques of Model-Driven Software Engineering (MDSE) and how can the right set of MDSE instruments be chosen for specific needs? 3. How can a new modeling language be created and what are the specific modeling issues and approaches in domains like business process modeling, user interaction modeling, and enterprise architecture?\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695446871273
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2rq = pd.read_csv('data_set_v2.1/paper_research_questions.tsv', sep='\\t', header=None, names=[\"paperId\",\"rq\"])\n",
        "\n",
        "for i in range(len(id2rq[\"rq\"])):\n",
        "    content = id2rq[\"rq\"][i]\n",
        "    paperId = id2rq[\"paperId\"][i]\n",
        "    temp_res = []\n",
        "    temp_res.append(content.split(\"1. \")[1].split(\"2. \")[0].strip())\n",
        "    temp_res.append(content.split(\"2. \")[1].split(\"3. \")[0].strip())\n",
        "    temp_res.append(content.split(\"3. \")[1].strip())\n",
        "    # print(temp_res)\n",
        "    paperJson[paperId][\"research_questions\"] = temp_res\n",
        "    # break"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694332575314
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('data_set_v2.1/paper_json_sampled_100.json', 'r',encoding='utf-8') as f:\n",
        "    paperJson = json.load(f)\n",
        "print(len(paperJson))\n",
        "with open('data_set_v2.1/author_json_sampled_100.json', 'r',encoding='utf-8') as f:\n",
        "    authorJson = json.load(f)\n",
        "print(len(authorJson))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "100\n536\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694525012270
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "from langdetect import detect\n",
        "def interstsValidation(interests, DictOfFields):\n",
        "    updated_interests = []\n",
        "    for i in interests:\n",
        "        updated_interests.extend(i.split(\"/\"))\n",
        "    # language check \n",
        "    lan = detect(\" \".join(interests))\n",
        "    # item count check \n",
        "    item_count = len(interests)\n",
        "    return interests\n",
        "\n",
        "for index,i in enumerate(authorJson):\n",
        "    DictOfFields = {}\n",
        "    for paper in authorJson[i][\"papers\"]:\n",
        "        if \"fieldsOfStudy\" in paper and paper[\"fieldsOfStudy\"] != None:\n",
        "            for field in paper[\"fieldsOfStudy\"]:\n",
        "                if field not in DictOfFields:\n",
        "                    DictOfFields[field] = 0\n",
        "                DictOfFields[field] = DictOfFields[field] +1 \n",
        "    interests = []\n",
        "    if \"interests\" in authorJson[i]:\n",
        "        interests = authorJson[i][\"interests\"]\n",
        "    interests = interstsValidation(interests, DictOfFields)\n",
        "    count = count + len(authorJson[i][\"papers\"])\n",
        "\n",
        "count / len(authorJson)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "LangDetectException",
          "evalue": "No features in text.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLangDetectException\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterests\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m authorJson[i]:\n\u001b[1;32m     24\u001b[0m         interests \u001b[38;5;241m=\u001b[39m authorJson[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterests\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m     interests \u001b[38;5;241m=\u001b[39m \u001b[43minterstsValidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDictOfFields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     count \u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(authorJson[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpapers\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     28\u001b[0m count \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(authorJson)\n",
            "Cell \u001b[0;32mIn[20], line 9\u001b[0m, in \u001b[0;36minterstsValidation\u001b[0;34m(interests, DictOfFields)\u001b[0m\n\u001b[1;32m      7\u001b[0m     updated_interests\u001b[38;5;241m.\u001b[39mextend(i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# language check \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m lan \u001b[38;5;241m=\u001b[39m \u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterests\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# item count check \u001b[39;00m\n\u001b[1;32m     11\u001b[0m item_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(interests)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/langdetect/detector_factory.py:130\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    128\u001b[0m detector \u001b[38;5;241m=\u001b[39m _factory\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m    129\u001b[0m detector\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/langdetect/detector.py:136\u001b[0m, in \u001b[0;36mDetector.detect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Detect language of the target text and return the language name\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    which has the highest probability.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m probabilities:\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlang\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/langdetect/detector.py:143\u001b[0m, in \u001b[0;36mDetector.get_probabilities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_probabilities\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_detect_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_probability(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/langdetect/detector.py:150\u001b[0m, in \u001b[0;36mDetector._detect_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m ngrams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_ngrams()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ngrams:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LangDetectException(ErrorCode\u001b[38;5;241m.\u001b[39mCantDetectError, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo features in text.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanglist)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n",
            "\u001b[0;31mLangDetectException\u001b[0m: No features in text."
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694509169348
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "'en'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694508768730
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}