{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1695472288052
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7931\n",
            "3275\n",
            "papers count after sampled:  100\n",
            "authors count after sampled:  243\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from heapq import nlargest\n",
        "import openai\n",
        "import torch\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "with open('data_set_v1.0/author_json.json', 'r',encoding='utf-8') as f:\n",
        "    authors = json.load(f)\n",
        "print(len(authors))\n",
        "\n",
        "with open('data_set_v1.0/paper_json.json', 'r',encoding='utf-8') as f:\n",
        "    papers = json.load(f)\n",
        "print(len(papers))\n",
        "# sampled papers to 500 \n",
        "count = 0\n",
        "max_paper = 100\n",
        "author_paper_count = []\n",
        "paper_author_count = []\n",
        "papers_sampled = {}\n",
        "authors_sampled = {}\n",
        "for i in papers:\n",
        "    if count < 100:\n",
        "        flag = True\n",
        "        for author in papers[i][\"authors\"]:\n",
        "            if len(authors[author][\"papers\"])<5:\n",
        "                flag = False\n",
        "        if flag and len(papers[i][\"authors\"]) > 1:\n",
        "            paper_author_count.append(len(papers[i][\"authors\"]))\n",
        "            papers_sampled[i] = papers[i]\n",
        "            papers_sampled[i][\"author_history\"] = {}\n",
        "            \n",
        "            for author in papers[i][\"authors\"]:\n",
        "                papers_sampled[i][\"author_history\"][author] = {}\n",
        "                papers_sampled[i][\"author_history\"][author][\"authors_history_text\"] = [papers[i][\"abstract\"]]\n",
        "                papers_sampled[i][\"author_history\"][author][\"authors_history_dict\"] = [{\"Abstract\":\"\",\"Title\":\"\"}]\n",
        "                paper_count_tmp = 0\n",
        "                for paper_tmp in authors[author][\"papers\"]:\n",
        "                    if paper_count_tmp < max_paper and paper_tmp[\"title\"] != papers[i][\"title\"]:\n",
        "                        papers_sampled[i][\"author_history\"][author][\"authors_history_text\"].append(\"Abstract: \"+paper_tmp[\"abstract\"]+\"\\nTitle: \"+paper_tmp[\"title\"])\n",
        "                        papers_sampled[i][\"author_history\"][author][\"authors_history_dict\"].append({\"Abstract\":paper_tmp[\"abstract\"],\"Title\":paper_tmp[\"title\"]})\n",
        "                        paper_count_tmp = paper_count_tmp + 1\n",
        "                author_paper_count.append(len(authors[author][\"papers\"]))\n",
        "                authors_sampled[author] = authors[author]\n",
        "            count = count + 1\n",
        "print(\"papers count after sampled: \",len(papers_sampled))\n",
        "print(\"authors count after sampled: \",len(authors_sampled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1695446871273
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 1. How can model-based approaches improve the daily practice of software professionals through Model-Driven Software Engineering (MDSE) or Model-Driven Engineering (MDE)? 2. What are the basic principles and techniques of MDSE that can be quickly understood and applied for immediate benefit? 3. How can the integration of MDSE in existing development processes be effectively achieved, and what are the technical aspects of MDSE, including the building of a domain-specific modeling language and the description of Model-to-Text and Model-to-Model transformations?\n",
            "1 1. How can a systematic mapping study be effectively conducted in the field of software engineering? 2. What are the key differences between systematic maps and systematic reviews in software engineering, and how can these differences guide the choice between them? 3. What are the guidelines for conducting systematic maps in software engineering based on the comparison with systematic reviews?\n",
            "2 1. What are the main issues and vulnerabilities associated with smart contract programming and other applications running on blockchains? 2. How could recognized best practices in software engineering mitigate the detrimental software misbehavior observed in the case of the Parity wallet application? 3. What specificities of Smart Contract software development make existing software engineering approaches insufficient, and what should be included in the definition of a specific Blockchain Software Engineering discipline to address these?\n",
            "3 1. What are the consistencies and inconsistencies in the research methods and terminologies used in Software Engineering (SE) research? 2. How does the ABC framework, which aims for generalizability over Actors and precise measurement of their Behavior in a realistic Context, apply to the research strategies in SE, particularly in the domains of global software engineering and requirements engineering? 3. In what ways can the ABC framework advance SE research and overcome the limitations inherent in the current research strategies?\n",
            "4 1. How effective and reliable are the three sentiment analysis tools specifically customized for software engineering in identifying developers' emotions? 2. What are the limitations of using off-the-shelf sentiment analysis tools in the software engineering domain? 3. What are the open challenges in sentiment analysis for software engineering, as identified from a qualitative analysis of misclassified texts?\n",
            "5 1. What are the key challenges in the accuracy of systems built using Machine Learning and AI models? 2. How can the testing of Machine Learning and AI-based systems be effectively conducted? 3. What are the practical implications and industrial applications of AI, and how can the rift between the Machine Learning and Software Engineering communities be bridged?\n",
            "6 1. What are the common aspects and trends in App Store Analysis that have been explored in previous research? 2. How can the findings from App Store Analysis be utilized for requirements engineering, release planning, software design, security and testing? 3. What are the potential directions for future research in App Store Analysis to address open problems and challenges?\n",
            "7 1. What are the variants of Grounded Theory (GT) and what constitutes the core set of GT practices? 2. How is Grounded Theory being utilized in the field of software engineering and what is the quality of these applications? 3. What guidelines can be established to improve the quality of conducting and reporting GT studies in software engineering, especially considering the current lack of guidelines for the reporting process?\n",
            "8 1. What are the main difficulties causing inaccuracies in automated sentiment analysis tools used in software engineering? 2. How can these identified difficulties be addressed in the development of a new tool, SentiStrength-SE, for improved sentiment analysis in the software engineering domain? 3. How does the performance of SentiStrength-SE, in terms of precision and recall, compare to existing state-of-the-art sentiment analysis tools in the software engineering field?\n",
            "9 1. How can the lexical gap between natural language search queries and code-based retrieved documents in software engineering be effectively bridged? 2. Can projecting natural language statements and code snippets as meaning vectors in a shared representation space improve information retrieval in software engineering? 3. How effective are the learned vector space embeddings in improving previously explored bug localization tasks and linking API documents to computer programming questions?\n",
            "10 1. How can model-based approaches improve the daily practice of software professionals and increase efficiency and effectiveness in software development? 2. What are the basic principles and techniques of Model-Driven Software Engineering (MDSE) and how can the right set of MDSE instruments be chosen for specific needs? 3. How can a new modeling language be created and what are the specific modeling issues and approaches in domains like business process modeling, user interaction modeling, and enterprise architecture?\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from heapq import nlargest\n",
        "import openai\n",
        "import torch\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import pandas as pd\n",
        "\n",
        "error_list=[]\n",
        "i = 0\n",
        "openai.api_key = \"\"\n",
        "openai.api_base = \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"\n",
        "openai.api_type = 'azure'\n",
        "openai.api_version = '2023-05-15' # this may change in the future\n",
        "key_bundles = [\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\")\n",
        "]\n",
        "    # prompt_construction v1.6\n",
        "def construct_prompt_cot_agg(paper):\n",
        "\n",
        "    prompt_str = \"\"\n",
        "    prompt_str = prompt_str + \"Assuming you’re the leading author of the following research paper, which contains title, abstract and a snippet of introduction. Please extract the research questions from it:\\n\"\n",
        "    prompt_str = prompt_str + \"Title:\" + paper[\"title\"] + \"\\n\"\n",
        "    prompt_str = prompt_str + \"Abstract:\" + paper[\"abstract\"] + \"\\n\"\n",
        "\n",
        "    prompt_str = prompt_str + \"Please extract top 3 research questions from the above information and make it a list\"+\"\\n\"\n",
        "    prompt_str = prompt_str + \"Research question: \"\n",
        "\n",
        "    return prompt_str\n",
        "\n",
        "\n",
        "def run_openai(prompt,key_bundles,i,indice):\n",
        "    my_dict = {}\n",
        "    my_dict[\"role\"] = \"user\"\n",
        "    my_dict[\"content\"] = prompt\n",
        "    l = []\n",
        "    l.append(my_dict)\n",
        "    result = \"\"\n",
        "    try:\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        response = openai.ChatCompletion.create(engine=\"gpt-4\", messages=l, temperature=0.0,request_timeout=30)\n",
        "        result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "        # print(indice+\"\\t\"+result+\"\\n\")\n",
        "        return result\n",
        "    except openai.error.Timeout:\n",
        "        i = i+1\n",
        "        print(\"Timeout\",indice)\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(engine=\"gpt-4\", messages=l, temperature=0.0,request_timeout=30)\n",
        "            result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "            # print(indice+\"\\t\"+result+\"\\n\")\n",
        "            return result\n",
        "        except openai.error.Timeout:\n",
        "            i = i+1\n",
        "            print(\"Timeout\",indice)\n",
        "            key_bundle = key_bundles[i%3]\n",
        "            openai.api_key, openai.api_base = key_bundle\n",
        "            try:\n",
        "                response = openai.ChatCompletion.create(engine=\"gpt-4\", messages=l, temperature=0.0,request_timeout=30)\n",
        "                result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "                # print(indice+\"\\t\"+result+\"\\n\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {str(e)}\")\n",
        "                error_list.append(i)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            error_list.append(i)\n",
        "        #print(result)\n",
        "    except openai.error.InvalidRequestError:\n",
        "        print(\"InvalidRequestError\",indice)\n",
        "        error_list.append(i)\n",
        "        #print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        error_list.append(i)\n",
        "    return result\n",
        "\n",
        "id2rq = {}\n",
        "with open(\"naive_method_v1.0/paper_research_questions.tsv\", \"wb\", buffering=0) as out_file:\n",
        "    for indice,paperId in enumerate(papers_sampled):\n",
        "        prompt = construct_prompt_cot_agg(papers_sampled[paperId])\n",
        "        # print(prompt)\n",
        "        # break\n",
        "        result = run_openai(prompt,key_bundles,i,indice)\n",
        "        print(indice, result)\n",
        "        id2rq[paperId] = result\n",
        "        write_str = bytes(str(paperId)+\"\\t\"+result+\"\\n\", 'utf-8')\n",
        "        out_file.write(write_str)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1694332575314
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "id2rq = pd.read_csv('data_set_v2.1/paper_research_questions.tsv', sep='\\t', header=None, names=[\"paperId\",\"rq\"])\n",
        "\n",
        "for i in range(len(id2rq[\"rq\"])):\n",
        "    content = id2rq[\"rq\"][i]\n",
        "    paperId = id2rq[\"paperId\"][i]\n",
        "    temp_res = []\n",
        "    temp_res.append(content.split(\"1. \")[1].split(\"2. \")[0].strip())\n",
        "    temp_res.append(content.split(\"2. \")[1].split(\"3. \")[0].strip())\n",
        "    temp_res.append(content.split(\"3. \")[1].strip())\n",
        "    # print(temp_res)\n",
        "    paperJson[paperId][\"research_questions\"] = temp_res\n",
        "    # break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1694525012270
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "536\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "with open('data_set_v2.1/paper_json_sampled_100.json', 'r',encoding='utf-8') as f:\n",
        "    paperJson = json.load(f)\n",
        "print(len(paperJson))\n",
        "with open('data_set_v2.1/author_json_sampled_100.json', 'r',encoding='utf-8') as f:\n",
        "    authorJson = json.load(f)\n",
        "print(len(authorJson))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1694509169348
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "from langdetect import detect\n",
        "def interstsValidation(interests, DictOfFields):\n",
        "    updated_interests = []\n",
        "    for i in interests:\n",
        "        updated_interests.extend(i.split(\"/\"))\n",
        "    # language check \n",
        "    lan = detect(\" \".join(interests))\n",
        "    # item count check \n",
        "    item_count = len(interests)\n",
        "    return interests\n",
        "\n",
        "for index,i in enumerate(authorJson):\n",
        "    DictOfFields = {}\n",
        "    for paper in authorJson[i][\"papers\"]:\n",
        "        if \"fieldsOfStudy\" in paper and paper[\"fieldsOfStudy\"] != None:\n",
        "            for field in paper[\"fieldsOfStudy\"]:\n",
        "                if field not in DictOfFields:\n",
        "                    DictOfFields[field] = 0\n",
        "                DictOfFields[field] = DictOfFields[field] +1 \n",
        "    interests = []\n",
        "    if \"interests\" in authorJson[i]:\n",
        "        interests = authorJson[i][\"interests\"]\n",
        "    interests = interstsValidation(interests, DictOfFields)\n",
        "    count = count + len(authorJson[i][\"papers\"])\n",
        "\n",
        "count / len(authorJson)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
