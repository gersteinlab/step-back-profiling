{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1696657461776
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "281\n",
            "107\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from heapq import nlargest\n",
        "import openai\n",
        "import torch\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "with open('../ScientificWritingDataset/authorJsonAndPaperJson/author_json.json', 'r',encoding='utf-8') as f:\n",
        "    authors_sampled = json.load(f)\n",
        "print(len(authors_sampled))\n",
        "\n",
        "with open('../ScientificWritingDataset/authorJsonAndPaperJson/paper_json.json', 'r',encoding='utf-8') as f:\n",
        "    papers_sampled = json.load(f)\n",
        "print(len(papers_sampled))\n",
        "# sampled papers to 500 \n",
        "# count = 0\n",
        "# max_paper = 100\n",
        "# author_paper_count = []\n",
        "# paper_author_count = []\n",
        "# papers_sampled = {}\n",
        "# authors_sampled = {}\n",
        "# for i in papers:\n",
        "#     if count < 100:\n",
        "#         flag = True\n",
        "#         for author in papers[i][\"authors\"]:\n",
        "#             if len(authors[author][\"papers\"])<5:\n",
        "#                 flag = False\n",
        "#         if flag and len(papers[i][\"authors\"]) > 1:\n",
        "#             paper_author_count.append(len(papers[i][\"authors\"]))\n",
        "#             papers_sampled[i] = papers[i]\n",
        "#             papers_sampled[i][\"author_history\"] = {}\n",
        "            \n",
        "#             for author in papers[i][\"authors\"]:\n",
        "#                 papers_sampled[i][\"author_history\"][author] = {}\n",
        "#                 papers_sampled[i][\"author_history\"][author][\"authors_history_text\"] = [papers[i][\"abstract\"]]\n",
        "#                 papers_sampled[i][\"author_history\"][author][\"authors_history_dict\"] = [{\"Abstract\":\"\",\"Title\":\"\"}]\n",
        "#                 paper_count_tmp = 0\n",
        "#                 for paper_tmp in authors[author][\"papers\"]:\n",
        "#                     if paper_count_tmp < max_paper and paper_tmp[\"title\"] != papers[i][\"title\"]:\n",
        "#                         papers_sampled[i][\"author_history\"][author][\"authors_history_text\"].append(\"Abstract: \"+paper_tmp[\"abstract\"]+\"\\nTitle: \"+paper_tmp[\"title\"])\n",
        "#                         papers_sampled[i][\"author_history\"][author][\"authors_history_dict\"].append({\"Abstract\":paper_tmp[\"abstract\"],\"Title\":paper_tmp[\"title\"]})\n",
        "#                         paper_count_tmp = paper_count_tmp + 1\n",
        "#                 author_paper_count.append(len(authors[author][\"papers\"]))\n",
        "#                 authors_sampled[author] = authors[author]\n",
        "#             count = count + 1\n",
        "# print(\"papers count after sampled: \",len(papers_sampled))\n",
        "# print(\"authors count after sampled: \",len(authors_sampled))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1696657486274
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "author_interests = pd.read_csv('../naive_method_v3.0/author_interests.tsv', sep='\\t', header=None, names=[\"authorId\",\"interests\"])\n",
        "author2interests = {}\n",
        "small_interests = 0\n",
        "small_interests_author_list = []\n",
        "\n",
        "for i in range(len(author_interests[\"authorId\"])):\n",
        "    authorId = author_interests[\"authorId\"][i]\n",
        "    interests = json.loads(author_interests[\"interests\"][i].replace(\"'\",\"\\\"\"))\n",
        "    if len(interests) <= 2:\n",
        "        small_interests = small_interests + 1\n",
        "        small_interests_author_list.append(authorId)\n",
        "    author2interests[author_interests[\"authorId\"][i]] = author_interests[\"interests\"][i]\n",
        "\n",
        "small_interests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1695905211202
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "error_list=[]\n",
        "i = 0\n",
        "openai.api_key = \"31b8638c9eea48709a596501490f9e88\"\n",
        "openai.api_base = \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"\n",
        "openai.api_type = 'azure'\n",
        "openai.api_version = '2023-05-15' # this may change in the future\n",
        "key_bundles = [\n",
        "    ('31b8638c9eea48709a596501490f9e88', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('31b8638c9eea48709a596501490f9e88', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('31b8638c9eea48709a596501490f9e88', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\")\n",
        "]\n",
        "\n",
        "    # prompt_construction v1.6\n",
        "def construct_prompt_cot_agg(author_dict,authorId):\n",
        "    prompt_str = \"\"\n",
        "\n",
        "    question_example = []\n",
        "    for index,item in enumerate(author_dict):\n",
        "        if index < 10:\n",
        "            question_example.append(\"Paper #\"+str(index)+\"\\nAbstract: \"+item[\"abstract\"]+\"\\nTitle: \"+item[\"title\"])\n",
        "\n",
        "    prompt_str = prompt_str + \"I give you some titles and paper abstracts that you've written. Please summarize your top 3 research interests.\\n\"\n",
        "    prompt_str = prompt_str + \"\\n\".join(question_example) + \"\\n\"\n",
        "    prompt_str = prompt_str + \"Please summarize top three key words that best represent your research interests in the format of \\\"['interest_1', 'interest_2', 'interest_3']\\\":\\n\"\n",
        "    prompt_str = prompt_str + \"Interests: \"\n",
        "\n",
        "    return prompt_str\n",
        "\n",
        "def run_openai(prompt,key_bundles,i,indice):\n",
        "    my_dict = {}\n",
        "    my_dict[\"role\"] = \"user\"\n",
        "    my_dict[\"content\"] = prompt\n",
        "    l = []\n",
        "    l.append(my_dict)\n",
        "    result = \"\"\n",
        "    try:\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "        result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "        # print(indice+\"\\t\"+result+\"\\n\")\n",
        "        return result\n",
        "    except openai.error.Timeout:\n",
        "        i = i+1\n",
        "        print(\"Timeout\",indice)\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "            result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "            # print(indice+\"\\t\"+result+\"\\n\")\n",
        "            return result\n",
        "        except openai.error.Timeout:\n",
        "            i = i+1\n",
        "            print(\"Timeout\",indice)\n",
        "            key_bundle = key_bundles[i%3]\n",
        "            openai.api_key, openai.api_base = key_bundle\n",
        "            try:\n",
        "                response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "                result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "                # print(indice+\"\\t\"+result+\"\\n\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {str(e)}\")\n",
        "                error_list.append(i)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            error_list.append(i)\n",
        "        #print(result)\n",
        "    except openai.error.InvalidRequestError:\n",
        "        print(\"InvalidRequestError\",indice)\n",
        "        error_list.append(i)\n",
        "        #print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        error_list.append(i)\n",
        "    return result\n",
        "\n",
        "# author2interests_llm = {}\n",
        "\n",
        "# for indice,authorId in enumerate(small_interests_author_list):\n",
        "#     prompt = construct_prompt_cot_agg(authors_sampled[str(authorId)][\"papers\"],authorId)\n",
        "#     # print(prompt)\n",
        "#     # break\n",
        "#     result = run_openai(prompt,key_bundles,i,indice)\n",
        "#     print(indice, result)\n",
        "#     # write_str = bytes(str(paperId)+\"\\t\"+str(authorId)+\"\\t\"+result+\"\\n\", 'utf-8')\n",
        "#     author2interests_llm[authorId]= result\n",
        "#     # out_file.write(write_str)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1696657556452
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "author2interests = {}\n",
        "for i in range(len(author_interests[\"authorId\"])):\n",
        "    authorId = author_interests[\"authorId\"][i]\n",
        "    interests = json.loads(author_interests[\"interests\"][i].replace(\"'\",\"\\\"\"))\n",
        "    if len(interests) <= 2:\n",
        "        author2interests[str(author_interests[\"authorId\"][i])] = json.loads(author2interests_llm[authorId].replace(\"'\",\"\\\"\"))\n",
        "    else:\n",
        "        author2interests[str(author_interests[\"authorId\"][i])] = interests[:3]\n",
        "\n",
        "with open(\"../naive_method_v1.0/author_interests.tsv\", \"wb\", buffering=0) as out_file:\n",
        "    for authorId in author2interests:\n",
        "        write_str = bytes(str(authorId)+\"\\t\"+str(author2interests[authorId])+\"\\n\", 'utf-8')\n",
        "        out_file.write(write_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1696657718782
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 ['Social media influence', 'Luxury brand marketing', 'AI robustness and explainability']\n",
            "1 ['Internet of Things', 'Software assistants', 'Model-driven engineering']\n",
            "2 ['Digital Twins', 'Model-Driven Engineering', 'Software Engineering']\n",
            "3 ['Regression testing', 'Software process improvement', 'Evidence-based decision-making']\n",
            "4 ['Automated testing', 'Test case prioritisation', 'Causal analysis of empirical data']\n",
            "5 ['Ethnomedicinal investigation', 'Product customization', 'Software product line variability']\n",
            "6 ['Software Product Line Engineering', 'Systematic Mapping Studies', 'Software Architecture Evaluation']\n",
            "7 ['Blockchain technology', 'Smart Contracts', 'Software engineering']\n",
            "8 ['Blockchain technology', 'Smart contracts', 'Software engineering']\n",
            "9 ['Smart Contracts', 'Blockchain Technology', 'Software Engineering']\n",
            "10 ['Blockchain software systems', 'Technical debt in open-source projects', 'Application of blockchain technology']\n",
            "11 ['Bitcoin-based decentralised applications', 'Noise and vibration measurements', 'Decentralized marketing model for online accommodation rental market']\n",
            "12 ['Metamorphic testing', 'Model-based testing', 'Causal inference']\n",
            "13 ['Sense of Virtual Community', 'Observational Techniques in Requirements Elicitation', 'Software Security Practice and Culture']\n",
            "14 ['Digital Contact Tracing', 'Episodic Volunteering', 'Rapid Continuous Software Engineering']\n",
            "15 ['Emotion awareness', 'Predictive models', 'Opinion mining']\n",
            "16 ['Emotion recognition', 'Biometric sensors', 'Software engineering']\n",
            "17 ['Emotion awareness', 'Predictive models for defectiveness', 'MLOps and AutoML']\n",
            "18 ['Machine Learning', 'Software Engineering', 'Ethical AI']\n",
            "19 ['Software development process', 'Machine learning models', 'Dependency management']\n",
            "20 ['Usability', 'GUI layout generation', 'Open source software']\n",
            "21 ['Internet of Things', 'Blockchain', 'DevOps']\n",
            "22 ['Reinforcement learning', 'Testing autonomous systems', 'Mutation testing']\n",
            "23 ['App Store Analysis', 'Causal Impact Analysis', 'Feature Lifecycle Analysis']\n",
            "24 ['Online Judge platforms', 'Serverless computing', 'Fairness in Machine Learning']\n",
            "25 ['Combinatorial Testing', 'Automated End-to-End Repair', 'Constraint Handling Techniques']\n",
            "26 ['Search-based software engineering', 'Empirical study', 'App store analysis']\n",
            "27 ['Code generation', 'Fairness improvement', 'Software testing']\n",
            "28 ['Remote work', 'Diversity and inclusion', 'Software engineering']\n",
            "29 ['Gender disparity in open-source projects', 'Name entity recognition in software engineering texts', 'Anomaly detection and active learning']\n",
            "30 ['Phishing detection', 'Security and privacy awareness', 'Bug fixing and software maintenance']\n",
            "31 ['Software Engineering', 'Information Retrieval', 'Collaborative Work']\n",
            "32 ['LSTM networks', 'information retrieval', 'sense disambiguation']\n",
            "33 ['Automated Financial Information Extraction', 'Information Retrieval in Software Engineering', 'Ontology Engineering for ICT Systems']\n",
            "34 ['Dysarthria diagnosis', 'Bug report classification', 'Software development awareness']\n",
            "35 ['Social media analysis', 'Natural language processing', 'Data-driven decision making']\n",
            "36 ['Dynamic Adaptive Systems', 'Fault Injection', 'Machine Learning in Industrial Processes']\n",
            "37 ['Automated diversity', 'Software bloat', 'Model-Based Software Engineering']\n",
            "38 ['Model-based approach', 'Edge computing applications', 'Internet of Things (IoT)']\n",
            "39 ['AI ethics', 'ethical requirements', 'software engineering']\n",
            "40 ['confirmation bias', 'software testing', 'cognitive biases']\n",
            "41 ['AI ethics', 'Search-based software testing', 'Human values in software engineering']\n",
            "42 ['Trust in software tools', 'AI-powered code generation tools', 'Open Source Software contributions']\n",
            "43 ['Trust in software tools', 'Code review recommendation systems', 'Collaborative software development']\n",
            "44 ['implementation design decisions', 'programming strategies', 'debugging behavior']\n",
            "45 ['Design knowledge capture', 'Collaboration tools in remote software teams', 'Software design and architecture']\n",
            "46 ['organizational agility', 'software development', 'security']\n",
            "47 ['ESG data quality', 'software engineering practices', 'service design']\n",
            "48 ['Collaborative Behavior', 'Motivations for Participation', 'Data-Driven Practices']\n",
            "49 ['Automated testing', 'Search-Based Software Testing', 'API testing']\n",
            "50 ['Automated Smell Detection and Recommendation', 'Data-driven Mutation Analysis', 'Stress Testing of Design Assumptions']\n",
            "51 ['malleable models', 'consistency management', 'model-based development']\n",
            "52 ['Information Systems Curriculum', 'Collaboration in Software Development Ecosystems', 'Research Topics in Computing Discipline']\n",
            "53 ['Qualitative analysis', 'GitHub bots', 'Static analysis alarms']\n",
            "54 ['Autonomous driving systems', 'Testing and scenario identification', 'Open data collaboration']\n",
            "55 ['Machine Learning', 'Gaze Data Analysis', 'Software Engineering']\n",
            "56 ['Reproducible searches', 'Virtual learning environment', 'Story-work in software engineering']\n",
            "57 ['Requirement prioritization', 'Change impact analysis', 'Scope tracking and visualization']\n",
            "58 ['Machine learning', 'Organizational structures in open-source software projects', 'Program comprehension']\n",
            "59 ['Configuration management', 'Software performance', 'Machine learning']\n",
            "60 ['Software engineering', 'Machine learning', 'Performance analysis']\n",
            "61 ['Developer experience', 'Software security practices', 'Continuous integration']\n",
            "62 ['Software development', 'Social aspects', 'Collaboration']\n",
            "63 ['arts-based approaches', 'entrepreneurial competencies', 'social media in software engineering']\n",
            "64 ['Human-Machine Learning', 'Software Bots', 'Social and Communication Channels in Software Development']\n",
            "65 ['Code similarity detection', 'Software engineering challenges', 'Test-to-code traceability']\n",
            "66 ['Genetic improvement', 'Genome assembly', 'Performance optimization']\n",
            "67 ['Genetic Improvement', 'Automated Program Repair', 'Software Product Line Engineering']\n",
            "68 ['Evidence-based research', 'Program comprehension', 'Psychometrics in software engineering']\n",
            "69 ['Large-scale agile transformations', 'Systematic Literature Reviews in Software Engineering', 'Impact of COVID-19 on software development activities']\n",
            "70 ['Impact of COVID-19 on software development activities', 'Impact investing in technology startups', 'Ethical considerations in AI software development']\n",
            "71 ['Online reinforcement learning', 'Adaptive systems', 'Data protection in edge computing']\n",
            "72 ['software engineering', 'code navigation strategies', 'eye-tracking studies']\n",
            "73 ['Eye tracking', 'Software development', 'Developer support']\n",
            "74 ['Eye tracking studies', 'Software engineering', 'Program comprehension']\n",
            "75 ['Automated video game testing', 'Legacy object-oriented systems', 'Game engine architecture recovery']\n",
            "76 ['MBSE', 'Technical Debt Management', 'Automation Software Engineering']\n",
            "77 ['Semantic interoperability', 'Automated risk assessments', 'Energy management systems']\n",
            "78 ['Industrial control design', 'Integration of flexible transport systems', 'Security-by-design decisions for cyber-physical systems']\n",
            "79 ['Software Engineering', 'Interdisciplinary Integration', 'Education Technology']\n",
            "80 ['Structural Analysis', 'Formal Specification', 'Model Checking']\n",
            "81 ['Digital Twins', 'Industrial Automation and Control Systems', 'Network Management']\n",
            "82 ['Festival Marketing', 'Complexity Science in Roman Studies', 'Research and Evaluation']\n",
            "83 ['Psychometrics', 'Behavioral software engineering', 'Human aspects of software engineering']\n",
            "84 ['Attitude towards change', 'Leadership development', 'Human factors in software engineering']\n",
            "85 ['Sustainable Manufacturing', 'Humanitarian Logistics', 'Supply Chain Optimization']\n",
            "86 ['Test cases prioritization', 'Software changes', 'Evolutionary algorithms']\n",
            "87 ['Ethical engineering mindset', 'Low-code development', 'Semi-supervised learning']\n",
            "88 ['Architectural Technical Debt', 'Refactoring', 'Software Maintenance']\n",
            "89 ['Eye tracking studies in software engineering', 'Accessibility in virtual environments', 'Collaborative software development for mixed-ability teams']\n",
            "90 ['Software development', 'Mobile programming', 'Text retrieval']\n",
            "91 ['Automating Code-Related Tasks', 'Deep Learning for Software Engineering', 'Code Recommender Systems']\n",
            "92 ['Automated software analysis', 'Mobile app development', 'Bug reporting and program repair']\n",
            "93 ['Code recommender systems', 'Predicting bugs', 'Quality of Docker artifacts']\n",
            "94 ['Quantum software engineering', 'Automated test case generation', 'Software maintenance and refactoring']\n",
            "95 ['software measurement processes', 'software test effort estimation', 'software size estimation']\n",
            "96 ['Bug localization', 'Bash scripting', 'Code analysis']\n",
            "97 ['Organizational structure patterns', 'Architecture smells', 'DevOps']\n",
            "98 ['Collaborative Model-Driven Software Engineering', 'Ethical considerations in software architecture', 'Sustainability in software engineering']\n",
            "99 ['Smart contracts', 'Code completion', 'Mobile UI testing']\n",
            "100 ['Profile-guided optimization', 'Parameterized unit testing', 'Software engineering education']\n",
            "101 ['Agile software development', 'Team performance', 'Empirical research']\n",
            "102 ['Construct validity', 'Microservices architecture', 'Empirical software engineering']\n",
            "103 ['IoT security', 'OpenAPI research', 'Software security in agile development']\n",
            "104 ['Efficient software development', 'Agile practices in global software engineering', 'Trust dynamics in global software engineering']\n",
            "105 ['Evidence-based decision-making', 'Systematic literature reviews', 'Knowledge translation']\n",
            "106 ['Automated Security Assessments', 'Reinforcement Learning', 'Attack Simulations']\n",
            "107 ['Software Bill of Materials', 'Time-To-Compromise', 'Cyber-Physical Systems']\n",
            "108 ['Software Engineering', 'Scrum', 'Object-Oriented Software Engineering']\n",
            "109 ['Resilient autonomous systems', 'Mission specification patterns', 'Uncertainty quantification']\n",
            "110 ['Self-adaptation', 'A/B testing', 'Software systems']\n",
            "111 ['Uncertainty quantification', 'Dynamic dependability management', 'Parametric model checking']\n",
            "112 ['self-adaptive systems', 'formal methods', 'uncertainties']\n",
            "113 ['Machine Learning', 'Safety Assurance', 'Ethics in AI']\n",
            "114 ['Automated safety analysis', 'Aircraft engine emissions', 'Safety and security assurance']\n",
            "115 ['Cloud resource management', 'Autonomic systems', 'Security control']\n",
            "116 ['Automatic Learning Path Creation', 'Synthetic Speech Detection', 'Design Pattern Detection']\n",
            "117 ['Renewable energy integration', 'Software engineering education', 'Agile software development']\n",
            "118 ['Software Engineering Education', 'Diversity in STEM', 'Requirements Engineering']\n",
            "119 ['Agile adoption', 'Backsourcing of software development', 'Large-scale agile development']\n",
            "120 ['Soft skills development', 'Agile methods', 'Scrum Master training']\n",
            "121 ['Open Source Software', 'Software Governance', 'Sustainability']\n",
            "122 ['Developer documentation format', 'Identifying concepts in software projects', 'Knowledge loss in software projects']\n",
            "123 ['Software product lines', 'Change impact analysis', 'API deprecation']\n",
            "124 ['Mathematics education', 'Debugging challenges in software development', 'Cooperative and human aspects of software engineering']\n",
            "125 ['Model-Based Software Engineering', 'User Experience (UX) in modeling tools', 'Software Design and Modeling']\n",
            "126 ['Artificial Intelligence Decision Making', 'Cybersickness induced by virtual reality', 'Software engineering work practices']\n",
            "127 ['software migration', 'software evolution', 'software architecture']\n",
            "128 ['Electric vehicles', 'Continuous integration', 'Software cost estimation']\n",
            "129 ['Competence growth', 'AI-based testing for autonomous vehicles', 'Generative AI for software practitioners']\n",
            "130 ['Hybrid software development', 'Transition to hybrid work', 'Gender diversity in software development']\n",
            "131 ['Global Software Development', 'Serious Games', 'Agile Software Development']\n",
            "132 ['Logging practices', 'Code review', 'Software engineering education']\n",
            "133 ['Spatial Digital Twins', 'Resource Utilization of Distributed Databases', 'UAV-enabled Edge Computing']\n",
            "134 ['Periodontal health', 'Denture loading', 'Photodynamic therapy']\n",
            "135 ['Machine Learning', 'Blockchain Technology', 'Environmental Monitoring']\n",
            "136 ['Software Engineering Guidelines', 'Evidence-Based Software Engineering', 'Systematic Literature Reviews']\n",
            "137 ['Software development management', 'Productivity factors in software development', 'Estimation bias in software development']\n",
            "138 ['AI-powered code assistants', 'Model behavior sensemaking', 'Exploratory data analysis']\n",
            "139 ['Flaky tests', 'Test optimization', 'Ramp-up journey of new hires']\n",
            "140 ['AI for Software Engineering', 'Code analysis and understanding', 'Automated software testing']\n",
            "141 ['Code search', 'Deep learning in software engineering', 'Temporal rules mining']\n",
            "142 ['Service-oriented architecture', 'Enterprise service computing', 'Design patterns']\n",
            "143 ['Enterprise Mobile Service Architecture', 'SLA-Aware Enterprise Service Computing', 'Design patterns']\n",
            "144 ['Design patterns', 'Software engineering', 'Semantic Web']\n",
            "145 ['Dynamic Systems-of-Systems', 'Autonomous Vehicles', 'Safety Assurance']\n",
            "146 ['Autonomous driving', 'Machine learning perception', 'Safety assurance']\n",
            "147 ['Knowledge graph', 'Machine learning', 'Cloud computing']\n",
            "148 ['FPGA Supercomputing', '0-1 knapsack problem', 'Antimonotonic functions']\n",
            "149 ['human-centered design', 'vocabulary learning', 'design knowledge']\n",
            "150 ['Julia programming language', 'Architectural analysis', 'Network anomaly detection']\n",
            "151 ['Design knowledge capture', 'Software maintenance meetings', 'Design rationale']\n",
            "152 ['outcomes assessment', 'inverted classroom', 'multicast tree algorithms']\n",
            "153 ['Augmented Agile', 'Ethics in AI', 'Empathy in Software Engineering']\n",
            "154 ['requirements engineering', 'software development', 'agile methods']\n",
            "155 ['Mobile edge computing', 'Software development', 'Requirements engineering']\n",
            "156 ['Large-scale agile software development', 'Feedback as a process', 'Coordination in software development']\n",
            "157 ['Software Engineering', 'Explainable AI', 'Complex Project Management']\n",
            "158 ['Software Engineering', 'Hybrid Project Management', 'Safety Engineering']\n",
            "159 ['Automated software engineering', 'Requirements-driven mediation for collaborative security', 'Formalisms and structures']\n",
            "160 ['Causal analysis', 'Practical significance', 'Technical debt']\n",
            "161 ['home automation systems', 'coronary artery disease', 'vulnerability prioritization']\n",
            "162 ['support models', 'family members', 'cancer trajectory']\n",
            "163 ['Discourse analysis', 'Digital humanities', 'Information extraction']\n",
            "164 ['Agent-oriented software engineering', 'Metamodel-driven software language engineering', 'Situational method engineering']\n",
            "165 ['Heterogeneous computing', 'Text classification', 'Memory disaggregation']\n",
            "166 ['cybersecurity', 'software development processes', 'information flow optimization']\n",
            "167 ['Autonomous systems', 'Model-based testing', 'Software architecture analysis']\n",
            "168 ['IoT-based predictive maintenance', 'Intrusion detection systems', 'Big data analytics']\n",
            "169 ['Conjoint Knowledge Discovery', 'Traffic Flow Forecasting', 'Accessing Data from Multiple Sources']\n",
            "170 ['Climate change', 'Blockchain technology', 'Social trust in online networks']\n",
            "171 ['Automotive software engineering', 'Regression test prioritization', 'Static code analysis']\n",
            "172 ['Semantics-Driven Modeling Languages', 'Architecture as a Backbone for Safe DevOps in Automotive Systems', 'Integrating Design Thinking for Human-Centered Requirements Engineering']\n",
            "173 ['Simulation-based training', 'Digitalization', 'Benefits management']\n",
            "174 ['Learning theories', 'Software engineering education', 'Simulation']\n",
            "175 ['workspace awareness', 'source code revision history visualization', 'virtual worlds for education']\n",
            "176 ['Architecture-centric development', 'Software architecture', 'Requirements engineering']\n",
            "177 ['Peripheral vision research', 'Complementary interfaces for visual computing', 'Adapting visualizations and interfaces to the user']\n",
            "178 ['Participatory platforms', 'Distributed computing systems', 'Crowdsensing']\n",
            "179 ['Transfer learning', 'Self-adaptive systems', 'Performance modelling']\n",
            "180 ['IoT edge analytics', 'Serverless computing', 'Resource allocation']\n",
            "181 ['Deep learning systems', 'Safety-critical self-adaptive systems', 'Environmental uncertainty']\n",
            "182 ['Robustification', 'Hyper-parameter tuning', 'Feature interactions']\n",
            "183 ['Software self-adaptation', 'Controllers based on microservices', 'Testing of adaptive and context-aware systems']\n",
            "184 ['adaptive systems', 'model learning', 'software architecture evolution']\n",
            "185 ['cognitive impairment', 'reading comprehension', 'assistive technology']\n",
            "186 ['Quantum computing', 'Digital twins', 'Cyber-Physical Systems']\n",
            "187 ['Software Configuration Management', 'Formal Specification-Driven Development', 'Software Protection']\n",
            "188 ['Software protection', 'Open source technology', 'Teaching with security in mind']\n",
            "189 ['Cybersecurity', 'Privacy', 'Healthcare']\n",
            "190 ['Consent Verification Monitoring', 'Real-Time BDI Agents', 'Privacy Protection in E-Government']\n",
            "191 ['Splunk Developer Platform', 'Microsoft Enterprise Library', 'Test-Driven Development']\n",
            "192 ['Enhancing Reservoir Engineering Workflows with Augmented and Virtual Reality', 'Towards a Systematic Mapping of Evidence-based UX Guidelines for Room-scale User Interfaces in Extended Reality', 'A Design Space for Single-User Cross-Reality Applications']\n",
            "193 ['digital urban democracy', 'sustainability', 'participatory design']\n",
            "194 ['Sustainability', 'Energy markets', 'Privacy in energy management systems']\n",
            "195 ['Sustainability', 'Software Engineering', 'Environmental Impact']\n",
            "196 ['Climate modeling', 'Video prediction', 'Deep learning']\n",
            "197 ['Sustainability', 'Software Engineering', 'Education']\n",
            "198 ['Sustainability in software development', 'Agile software development and sustainability', 'Crowd-based requirements engineering']\n",
            "199 ['Sustainability', 'Software Engineering', 'Requirements Engineering']\n",
            "200 ['Surface modification', 'Chemical bonding', 'Architectural decisions']\n",
            "201 ['Virtual Reality', 'Software Engineering Methodology', 'Software Product Lines']\n",
            "202 ['Architectural Technical Debt', 'Code Review', 'Software Maintenance']\n",
            "203 ['context-awareness', 'software engineering', 'pervasive computing']\n",
            "204 ['Trust management frameworks', 'Load balancing', 'Activity recognition']\n",
            "205 ['neural-symbolic reinforcement learning', 'agent-oriented programming language', 'indoor positioning']\n",
            "206 ['Adaptive Multi-Agent Systems', 'Cooperative Neighborhood Learning', 'Smart City']\n",
            "207 ['Edge Digital Twins', 'Distributed coordination', 'Autonomous development']\n",
            "208 ['Inclusive design', 'CS education', 'Human-AI interaction']\n",
            "209 ['decision making', 'gender differences', 'end-user programming']\n",
            "210 ['test case prioritization', 'automated UI testing', 'software engineering']\n",
            "211 ['Early warning detection', 'Physiological measurements', 'Machine learning']\n",
            "212 ['Cloud-based game streaming', 'Latency compensation techniques', 'TCP congestion control']\n",
            "213 ['software development', 'dynamic capabilities', 'software business']\n",
            "214 ['Digital trace data analysis', 'Design science research', 'Binge-watching behavior']\n",
            "215 ['Agile software projects', 'Software qualities and dependencies', 'Multimodal learning']\n",
            "216 ['Machine/Deep Learning for Software Engineering', 'Bug Localization', 'Code Completion']\n",
            "217 ['mental health screening', 'collaborative brainstorming', 'software development']\n",
            "218 ['build system variability', 'software evolution', 'optimistic replication']\n",
            "219 ['adaptive security systems', 'spatially distributed systems', 'model-driven design']\n",
            "220 ['Temporal logics', 'Operator Precedence Languages', 'Model checking']\n"
          ]
        }
      ],
      "source": [
        "openai.api_key = \"0de53d4ada864cd18e3771d16551aee1\"\n",
        "openai.api_base = \"https://biocodeeval-openai.openai.azure.com/\"\n",
        "openai.api_type = 'azure'\n",
        "openai.api_version = '2023-05-15' # this may change in the future\n",
        "key_bundles = [\n",
        "    ('0de53d4ada864cd18e3771d16551aee1', \"https://biocodeeval-openai.openai.azure.com/\"),\n",
        "    ('0de53d4ada864cd18e3771d16551aee1', \"https://biocodeeval-openai.openai.azure.com/\"),\n",
        "    ('0de53d4ada864cd18e3771d16551aee1', \"https://biocodeeval-openai.openai.azure.com/\")\n",
        "]\n",
        "\n",
        "    # prompt_construction v1.6\n",
        "def construct_prompt_task_1(author_dict,authorId):\n",
        "    prompt_str = \"\"\n",
        "\n",
        "    question_example = []\n",
        "    for index,item in enumerate(author_dict):\n",
        "        if index < 15:\n",
        "            question_example.append(\"Paper #\"+str(index)+\"\\nAbstract: \"+item[\"abstract\"]+\"\\nTitle: \"+item[\"title\"])\n",
        "\n",
        "    prompt_str = prompt_str + \"You will be given some science papers that you've written, each of them contains a title and a abstract that you've written. Please summarize your top 3 research interests.\\n\"\n",
        "    prompt_str = prompt_str + \"\\n\".join(question_example) + \"\\n\"\n",
        "    prompt_str = prompt_str + \"Please summarize top three key words that best represent your research interests in the format of \\\"['interest_1', 'interest_2', 'interest_3']\\\":\\n\"\n",
        "    prompt_str = prompt_str + \"Interests: \"\n",
        "\n",
        "    return prompt_str\n",
        "\n",
        "def run_openai(prompt,key_bundles,i,indice):\n",
        "    my_dict = {}\n",
        "    my_dict[\"role\"] = \"user\"\n",
        "    my_dict[\"content\"] = prompt\n",
        "    l = []\n",
        "    l.append(my_dict)\n",
        "    result = \"\"\n",
        "    try:\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        response = openai.ChatCompletion.create(engine=\"gpt-35-turbo-16k\", messages=l, temperature=0.0,request_timeout=30)\n",
        "        result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "        # print(indice+\"\\t\"+result+\"\\n\")\n",
        "        return result\n",
        "    except openai.error.Timeout:\n",
        "        i = i+1\n",
        "        print(\"Timeout\",indice)\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(engine=\"gpt-35-turbo-16k\", messages=l, temperature=0.0,request_timeout=30)\n",
        "            result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "            # print(indice+\"\\t\"+result+\"\\n\")\n",
        "            return result\n",
        "        except openai.error.Timeout:\n",
        "            i = i+1\n",
        "            print(\"Timeout\",indice)\n",
        "            key_bundle = key_bundles[i%3]\n",
        "            openai.api_key, openai.api_base = key_bundle\n",
        "            try:\n",
        "                response = openai.ChatCompletion.create(engine=\"gpt-35-turbo-16k\", messages=l, temperature=0.0,request_timeout=30)\n",
        "                result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "                # print(indice+\"\\t\"+result+\"\\n\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {str(e)}\")\n",
        "                error_list.append(i)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            error_list.append(i)\n",
        "        #print(result)\n",
        "    except openai.error.InvalidRequestError:\n",
        "        print(\"InvalidRequestError\",indice)\n",
        "        error_list.append(i)\n",
        "        #print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        error_list.append(i)\n",
        "    return result\n",
        "\n",
        "id2interest_pred = {}\n",
        "with open(\"author_interests_prediction_v1.0.tsv\", \"wb\", buffering=0) as out_file:\n",
        "    for i,authorId in enumerate(author2interests):\n",
        "        prompt = construct_prompt_task_1(authors_sampled[authorId][\"papers\"],authorId)\n",
        "        result = run_openai(prompt,key_bundles,i,i)\n",
        "        id2interest_pred[authorId] = json.loads(result.replace(\"'\",\"\\\"\"))\n",
        "        print(i, result)\n",
        "        write_str = bytes(str(authorId)+\"\\t\"+result+\"\\n\", 'utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1696659730878
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-07 06:21:49.682057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-07 06:22:00.521794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-10-07 06:22:00.522164: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-10-07 06:22:00.522199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge-1': 0.2559858557662884, 'rouge-L': 0.2299960483212423}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from rouge import Rouge\n",
        "import evaluate\n",
        "def postprocess_text_generation(preds, labels):\n",
        "    preds = [\" \".join(pred).replace(\"\\\"\",\"\").strip() for pred in preds]\n",
        "    labels = [[\" \".join(label).strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "def create_metric_rouge():\n",
        "    rouge_metric = evaluate.load('rouge')\n",
        "    def compute_metrics(decoded_preds, decoded_labels):\n",
        "        decoded_preds, decoded_labels = postprocess_text_generation(decoded_preds, decoded_labels)\n",
        "        result_rouge = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "        result = {\"rouge-1\" : result_rouge[\"rouge1\"], \"rouge-L\" : result_rouge[\"rougeL\"]}\n",
        "        return result\n",
        "    return compute_metrics\n",
        "pred = []\n",
        "gold = []\n",
        "for i in id2interest_pred:\n",
        "    if i in authors_sampled and i in id2interest_pred:\n",
        "        pred.append(id2interest_pred[i])\n",
        "        gold.append(author2interests[i])\n",
        "# print(pred)\n",
        "metric = create_metric_rouge()\n",
        "print(metric(pred, gold))\n",
        "# results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1695905749916
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "0 informativeness 3\n",
            "3\n",
            "0 novelty 3\n",
            "4\n",
            "1 informativeness 4\n",
            "3\n",
            "1 novelty 3\n",
            "3\n",
            "2 informativeness 3\n",
            "2\n",
            "2 novelty 2\n",
            "4\n",
            "3 informativeness 4\n",
            "2\n",
            "3 novelty 2\n",
            "4\n",
            "4 informativeness 4\n",
            "3\n",
            "4 novelty 3\n",
            "3\n",
            "5 informativeness 3\n",
            "3\n",
            "5 novelty 3\n",
            "3\n",
            "6 informativeness 3\n",
            "2\n",
            "6 novelty 2\n",
            "4\n",
            "7 informativeness 4\n",
            "2\n",
            "7 novelty 2\n",
            "4\n",
            "8 informativeness 4\n",
            "2\n",
            "8 novelty 2\n",
            "3\n",
            "9 informativeness 3\n",
            "3\n",
            "9 novelty 3\n",
            "3\n",
            "10 informativeness 3\n",
            "2\n",
            "10 novelty 2\n",
            "3\n",
            "11 informativeness 3\n",
            "2\n",
            "11 novelty 2\n",
            "4\n",
            "12 informativeness 4\n",
            "3\n",
            "12 novelty 3\n",
            "3\n",
            "13 informativeness 3\n",
            "2\n",
            "13 novelty 2\n",
            "2\n",
            "14 informativeness 2\n",
            "2\n",
            "14 novelty 2\n",
            "4\n",
            "15 informativeness 4\n",
            "3\n",
            "15 novelty 3\n",
            "3\n",
            "16 informativeness 3\n",
            "2\n",
            "16 novelty 2\n",
            "2\n",
            "17 informativeness 2\n",
            "2\n",
            "17 novelty 2\n",
            "4\n",
            "18 informativeness 4\n",
            "3\n",
            "18 novelty 3\n",
            "4\n",
            "19 informativeness 4\n",
            "2\n",
            "19 novelty 2\n",
            "3\n",
            "20 informativeness 3\n",
            "3\n",
            "20 novelty 3\n",
            "3\n",
            "21 informativeness 3\n",
            "3\n",
            "21 novelty 3\n",
            "4\n",
            "22 informativeness 4\n",
            "2\n",
            "22 novelty 2\n",
            "3\n",
            "23 informativeness 3\n",
            "2\n",
            "23 novelty 2\n",
            "4\n",
            "24 informativeness 4\n",
            "3\n",
            "24 novelty 3\n",
            "4\n",
            "25 informativeness 4\n",
            "3\n",
            "25 novelty 3\n",
            "4\n",
            "26 informativeness 4\n",
            "2\n",
            "26 novelty 2\n",
            "4\n",
            "27 informativeness 4\n",
            "2\n",
            "27 novelty 2\n",
            "4\n",
            "28 informativeness 4\n",
            "2\n",
            "28 novelty 2\n",
            "4\n",
            "29 informativeness 4\n",
            "1: Gender disparity in open-source projects - 3 2: Name entity recognition in software engineering texts - 2 3: Anomaly detection and active learning - 2\n",
            "29 novelty 1: Gender disparity in open-source projects - 3 2: Name entity recognition in software engineering texts - 2 3: Anomaly detection and active learning - 2\n",
            "2\n",
            "30 informativeness 2\n",
            "2\n",
            "30 novelty 2\n",
            "3\n",
            "31 informativeness 3\n",
            "2\n",
            "31 novelty 2\n",
            "4\n",
            "32 informativeness 4\n",
            "3\n",
            "32 novelty 3\n",
            "2\n",
            "33 informativeness 2\n",
            "3\n",
            "33 novelty 3\n",
            "2\n",
            "34 informativeness 2\n",
            "2\n",
            "34 novelty 2\n",
            "4\n",
            "35 informativeness 4\n",
            "2\n",
            "35 novelty 2\n",
            "4\n",
            "36 informativeness 4\n",
            "3\n",
            "36 novelty 3\n",
            "3\n",
            "37 informativeness 3\n",
            "3\n",
            "37 novelty 3\n",
            "4\n",
            "38 informativeness 4\n",
            "2\n",
            "38 novelty 2\n",
            "3\n",
            "39 informativeness 3\n",
            "2\n",
            "39 novelty 2\n",
            "3\n",
            "40 informativeness 3\n",
            "3\n",
            "40 novelty 3\n",
            "4\n",
            "41 informativeness 4\n",
            "3\n",
            "41 novelty 3\n",
            "3\n",
            "42 informativeness 3\n",
            "2\n",
            "42 novelty 2\n",
            "4\n",
            "43 informativeness 4\n",
            "2\n",
            "43 novelty 2\n",
            "2\n",
            "44 informativeness 2\n",
            "2\n",
            "44 novelty 2\n",
            "4\n",
            "45 informativeness 4\n",
            "2\n",
            "45 novelty 2\n",
            "3\n",
            "46 informativeness 3\n",
            "2\n",
            "46 novelty 2\n",
            "3\n",
            "47 informativeness 3\n",
            "2\n",
            "47 novelty 2\n",
            "3\n",
            "48 informativeness 3\n",
            "2\n",
            "48 novelty 2\n",
            "3\n",
            "49 informativeness 3\n",
            "2\n",
            "49 novelty 2\n",
            "3\n",
            "50 informativeness 3\n",
            "3\n",
            "50 novelty 3\n",
            "3\n",
            "51 informativeness 3\n",
            "2\n",
            "51 novelty 2\n",
            "3\n",
            "52 informativeness 3\n",
            "2\n",
            "52 novelty 2\n",
            "3\n",
            "53 informativeness 3\n",
            "2\n",
            "53 novelty 2\n",
            "4\n",
            "54 informativeness 4\n",
            "2\n",
            "54 novelty 2\n",
            "3\n",
            "55 informativeness 3\n",
            "2\n",
            "55 novelty 2\n",
            "3\n",
            "56 informativeness 3\n",
            "1\n",
            "56 novelty 1\n",
            "3\n",
            "57 informativeness 3\n",
            "2\n",
            "57 novelty 2\n",
            "4\n",
            "58 informativeness 4\n",
            "2\n",
            "58 novelty 2\n",
            "4\n",
            "59 informativeness 4\n",
            "2\n",
            "59 novelty 2\n",
            "4\n",
            "60 informativeness 4\n",
            "2\n",
            "60 novelty 2\n",
            "3\n",
            "61 informativeness 3\n",
            "2\n",
            "61 novelty 2\n",
            "3\n",
            "62 informativeness 3\n",
            "3\n",
            "62 novelty 3\n",
            "3\n",
            "63 informativeness 3\n",
            "3\n",
            "63 novelty 3\n",
            "3\n",
            "64 informativeness 3\n",
            "3\n",
            "64 novelty 3\n",
            "4\n",
            "65 informativeness 4\n",
            "3\n",
            "65 novelty 3\n",
            "4\n",
            "66 informativeness 4\n",
            "2\n",
            "66 novelty 2\n",
            "3\n",
            "67 informativeness 3\n",
            "3\n",
            "67 novelty 3\n",
            "4\n",
            "68 informativeness 4\n",
            "3\n",
            "68 novelty 3\n",
            "4\n",
            "69 informativeness 4\n",
            "2\n",
            "69 novelty 2\n",
            "4\n",
            "70 informativeness 4\n",
            "Impact of COVID-19 on software development activities: 2 Impact investing in technology startups: 2 Ethical considerations in AI software development: 3\n",
            "70 novelty Impact of COVID-19 on software development activities: 2 Impact investing in technology startups: 2 Ethical considerations in AI software development: 3\n",
            "3\n",
            "71 informativeness 3\n",
            "3\n",
            "71 novelty 3\n",
            "4\n",
            "72 informativeness 4\n",
            "3\n",
            "72 novelty 3\n",
            "3\n",
            "73 informativeness 3\n",
            "2\n",
            "73 novelty 2\n",
            "4\n",
            "74 informativeness 4\n",
            "2\n",
            "74 novelty 2\n",
            "3\n",
            "75 informativeness 3\n",
            "2\n",
            "75 novelty 2\n",
            "3\n",
            "76 informativeness 3\n",
            "2\n",
            "76 novelty 2\n",
            "4\n",
            "77 informativeness 4\n",
            "2\n",
            "77 novelty 2\n",
            "4\n",
            "78 informativeness 4\n",
            "3\n",
            "78 novelty 3\n",
            "3\n",
            "79 informativeness 3\n",
            "3\n",
            "79 novelty 3\n",
            "4\n",
            "80 informativeness 4\n",
            "3\n",
            "80 novelty 3\n",
            "3\n",
            "81 informativeness 3\n",
            "2\n",
            "81 novelty 2\n",
            "2\n",
            "82 informativeness 2\n",
            "2\n",
            "82 novelty 2\n",
            "3\n",
            "83 informativeness 3\n",
            "3\n",
            "83 novelty 3\n",
            "4\n",
            "84 informativeness 4\n",
            "2\n",
            "84 novelty 2\n",
            "4\n",
            "85 informativeness 4\n",
            "3\n",
            "85 novelty 3\n",
            "4\n",
            "86 informativeness 4\n",
            "2\n",
            "86 novelty 2\n",
            "3\n",
            "87 informativeness 3\n",
            "2\n",
            "87 novelty 2\n",
            "4\n",
            "88 informativeness 4\n",
            "2\n",
            "88 novelty 2\n",
            "5\n",
            "89 informativeness 5\n",
            "2\n",
            "89 novelty 2\n",
            "3\n",
            "90 informativeness 3\n",
            "2\n",
            "90 novelty 2\n",
            "4\n",
            "91 informativeness 4\n",
            "2\n",
            "91 novelty 2\n",
            "4\n",
            "92 informativeness 4\n",
            "2\n",
            "92 novelty 2\n",
            "3\n",
            "93 informativeness 3\n",
            "3\n",
            "93 novelty 3\n",
            "4\n",
            "94 informativeness 4\n",
            "2\n",
            "94 novelty 2\n",
            "4\n",
            "95 informativeness 4\n",
            "2\n",
            "95 novelty 2\n",
            "4\n",
            "96 informativeness 4\n",
            "2\n",
            "96 novelty 2\n",
            "3\n",
            "97 informativeness 3\n",
            "3\n",
            "97 novelty 3\n",
            "3\n",
            "98 informativeness 3\n",
            "2\n",
            "98 novelty 2\n",
            "3\n",
            "99 informativeness 3\n",
            "2\n",
            "99 novelty 2\n",
            "4\n",
            "100 informativeness 4\n",
            "2\n",
            "100 novelty 2\n",
            "4\n",
            "101 informativeness 4\n",
            "2\n",
            "101 novelty 2\n",
            "4\n",
            "102 informativeness 4\n",
            "3\n",
            "102 novelty 3\n",
            "3\n",
            "103 informativeness 3\n",
            "2\n",
            "103 novelty 2\n",
            "3\n",
            "104 informativeness 3\n",
            "2\n",
            "104 novelty 2\n",
            "3\n",
            "105 informativeness 3\n",
            "2\n",
            "105 novelty 2\n",
            "3\n",
            "106 informativeness 3\n",
            "3\n",
            "106 novelty 3\n",
            "4\n",
            "107 informativeness 4\n",
            "3\n",
            "107 novelty 3\n",
            "3\n",
            "108 informativeness 3\n",
            "2\n",
            "108 novelty 2\n",
            "4\n",
            "109 informativeness 4\n",
            "3\n",
            "109 novelty 3\n",
            "4\n",
            "110 informativeness 4\n",
            "2\n",
            "110 novelty 2\n",
            "4\n",
            "111 informativeness 4\n",
            "3\n",
            "111 novelty 3\n",
            "3\n",
            "112 informativeness 3\n",
            "3\n",
            "112 novelty 3\n",
            "4\n",
            "113 informativeness 4\n",
            "3\n",
            "113 novelty 3\n",
            "4\n",
            "114 informativeness 4\n",
            "2\n",
            "114 novelty 2\n",
            "3\n",
            "115 informativeness 3\n",
            "2\n",
            "115 novelty 2\n",
            "3\n",
            "116 informativeness 3\n",
            "3\n",
            "116 novelty 3\n",
            "3\n",
            "117 informativeness 3\n",
            "2\n",
            "117 novelty 2\n",
            "3\n",
            "118 informativeness 3\n",
            "2\n",
            "118 novelty 2\n",
            "3\n",
            "119 informativeness 3\n",
            "2\n",
            "119 novelty 2\n",
            "2\n",
            "120 informativeness 2\n",
            "2\n",
            "120 novelty 2\n",
            "3\n",
            "121 informativeness 3\n",
            "2\n",
            "121 novelty 2\n",
            "4\n",
            "122 informativeness 4\n",
            "2\n",
            "122 novelty 2\n",
            "3\n",
            "123 informativeness 3\n",
            "2\n",
            "123 novelty 2\n",
            "3\n",
            "124 informativeness 3\n",
            "2\n",
            "124 novelty 2\n",
            "3\n",
            "125 informativeness 3\n",
            "2\n",
            "125 novelty 2\n",
            "2\n",
            "126 informativeness 2\n",
            "2\n",
            "126 novelty 2\n",
            "3\n",
            "127 informativeness 3\n",
            "2\n",
            "127 novelty 2\n",
            "3\n",
            "128 informativeness 3\n",
            "2\n",
            "128 novelty 2\n",
            "3\n",
            "129 informativeness 3\n",
            "2\n",
            "129 novelty 2\n",
            "3\n",
            "130 informativeness 3\n",
            "2\n",
            "130 novelty 2\n",
            "3\n",
            "131 informativeness 3\n",
            "2\n",
            "131 novelty 2\n",
            "3\n",
            "132 informativeness 3\n",
            "2\n",
            "132 novelty 2\n",
            "3\n",
            "133 informativeness 3\n",
            "3\n",
            "133 novelty 3\n",
            "3\n",
            "134 informativeness 3\n",
            "3\n",
            "134 novelty 3\n",
            "4\n",
            "135 informativeness 4\n",
            "3\n",
            "135 novelty 3\n",
            "4\n",
            "136 informativeness 4\n",
            "2\n",
            "136 novelty 2\n",
            "4\n",
            "137 informativeness 4\n",
            "2\n",
            "137 novelty 2\n",
            "3\n",
            "138 informativeness 3\n",
            "3\n",
            "138 novelty 3\n",
            "2\n",
            "139 informativeness 2\n",
            "2\n",
            "139 novelty 2\n",
            "4\n",
            "140 informativeness 4\n",
            "2\n",
            "140 novelty 2\n",
            "4\n",
            "141 informativeness 4\n",
            "3\n",
            "141 novelty 3\n",
            "4\n",
            "142 informativeness 4\n",
            "2\n",
            "142 novelty 2\n",
            "2\n",
            "143 informativeness 2\n",
            "2\n",
            "143 novelty 2\n",
            "3\n",
            "144 informativeness 3\n",
            "2\n",
            "144 novelty 2\n",
            "3\n",
            "145 informativeness 3\n",
            "3\n",
            "145 novelty 3\n",
            "4\n",
            "146 informativeness 4\n",
            "2\n",
            "146 novelty 2\n",
            "4\n",
            "147 informativeness 4\n",
            "3\n",
            "147 novelty 3\n",
            "3\n",
            "148 informativeness 3\n",
            "3\n",
            "148 novelty 3\n",
            "3\n",
            "149 informativeness 3\n",
            "3\n",
            "149 novelty 3\n",
            "4\n",
            "150 informativeness 4\n",
            "3\n",
            "150 novelty 3\n",
            "3\n",
            "151 informativeness 3\n",
            "2\n",
            "151 novelty 2\n",
            "3\n",
            "152 informativeness 3\n",
            "2\n",
            "152 novelty 2\n",
            "2\n",
            "153 informativeness 2\n",
            "3\n",
            "153 novelty 3\n",
            "4\n",
            "154 informativeness 4\n",
            "2\n",
            "154 novelty 2\n",
            "3\n",
            "155 informativeness 3\n",
            "2\n",
            "155 novelty 2\n",
            "3\n",
            "156 informativeness 3\n",
            "2\n",
            "156 novelty 2\n",
            "3\n",
            "157 informativeness 3\n",
            "3\n",
            "157 novelty 3\n",
            "3\n",
            "158 informativeness 3\n",
            "2\n",
            "158 novelty 2\n",
            "3\n",
            "159 informativeness 3\n",
            "3\n",
            "159 novelty 3\n",
            "3\n",
            "160 informativeness 3\n",
            "3\n",
            "160 novelty 3\n",
            "2\n",
            "161 informativeness 2\n",
            "3\n",
            "161 novelty 3\n",
            "3\n",
            "162 informativeness 3\n",
            "3\n",
            "162 novelty 3\n",
            "4\n",
            "163 informativeness 4\n",
            "3\n",
            "163 novelty 3\n",
            "4\n",
            "164 informativeness 4\n",
            "3\n",
            "164 novelty 3\n",
            "4\n",
            "165 informativeness 4\n",
            "2\n",
            "165 novelty 2\n",
            "3\n",
            "166 informativeness 3\n",
            "2\n",
            "166 novelty 2\n",
            "4\n",
            "167 informativeness 4\n",
            "2\n",
            "167 novelty 2\n",
            "4\n",
            "168 informativeness 4\n",
            "2\n",
            "168 novelty 2\n",
            "3\n",
            "169 informativeness 3\n",
            "2\n",
            "169 novelty 2\n",
            "3\n",
            "170 informativeness 3\n",
            "3\n",
            "170 novelty 3\n",
            "4\n",
            "171 informativeness 4\n",
            "2\n",
            "171 novelty 2\n",
            "2\n",
            "172 informativeness 2\n",
            "3\n",
            "172 novelty 3\n",
            "3\n",
            "173 informativeness 3\n",
            "2\n",
            "173 novelty 2\n",
            "3\n",
            "174 informativeness 3\n",
            "3\n",
            "174 novelty 3\n",
            "3\n",
            "175 informativeness 3\n",
            "3\n",
            "175 novelty 3\n",
            "4\n",
            "176 informativeness 4\n",
            "2\n",
            "176 novelty 2\n",
            "3\n",
            "177 informativeness 3\n",
            "2\n",
            "177 novelty 2\n",
            "3\n",
            "178 informativeness 3\n",
            "3\n",
            "178 novelty 3\n",
            "4\n",
            "179 informativeness 4\n",
            "3\n",
            "179 novelty 3\n",
            "4\n",
            "180 informativeness 4\n",
            "2\n",
            "180 novelty 2\n",
            "3\n",
            "181 informativeness 3\n",
            "3\n",
            "181 novelty 3\n",
            "3\n",
            "182 informativeness 3\n",
            "3\n",
            "182 novelty 3\n",
            "4\n",
            "183 informativeness 4\n",
            "3\n",
            "183 novelty 3\n",
            "4\n",
            "184 informativeness 4\n",
            "3\n",
            "184 novelty 3\n",
            "4\n",
            "185 informativeness 4\n",
            "3\n",
            "185 novelty 3\n",
            "3\n",
            "186 informativeness 3\n",
            "2\n",
            "186 novelty 2\n",
            "3\n",
            "187 informativeness 3\n",
            "3\n",
            "187 novelty 3\n",
            "2\n",
            "188 informativeness 2\n",
            "2\n",
            "188 novelty 2\n",
            "3\n",
            "189 informativeness 3\n",
            "3\n",
            "189 novelty 3\n",
            "3\n",
            "190 informativeness 3\n",
            "3\n",
            "190 novelty 3\n",
            "2\n",
            "191 informativeness 2\n",
            "2\n",
            "191 novelty 2\n",
            "3\n",
            "192 informativeness 3\n",
            "1\n",
            "192 novelty 1\n",
            "3\n",
            "193 informativeness 3\n",
            "3\n",
            "193 novelty 3\n",
            "3\n",
            "194 informativeness 3\n",
            "3\n",
            "194 novelty 3\n",
            "4\n",
            "195 informativeness 4\n",
            "3\n",
            "195 novelty 3\n",
            "3\n",
            "196 informativeness 3\n",
            "2\n",
            "196 novelty 2\n",
            "3\n",
            "197 informativeness 3\n",
            "3\n",
            "197 novelty 3\n",
            "3\n",
            "198 informativeness 3\n",
            "3\n",
            "198 novelty 3\n",
            "3\n",
            "199 informativeness 3\n",
            "3\n",
            "199 novelty 3\n",
            "2\n",
            "200 informativeness 2\n",
            "3\n",
            "200 novelty 3\n",
            "3\n",
            "201 informativeness 3\n",
            "2\n",
            "201 novelty 2\n",
            "3\n",
            "202 informativeness 3\n",
            "2\n",
            "202 novelty 2\n",
            "3\n",
            "203 informativeness 3\n",
            "3\n",
            "203 novelty 3\n",
            "3\n",
            "204 informativeness 3\n",
            "2\n",
            "204 novelty 2\n",
            "3\n",
            "205 informativeness 3\n",
            "3\n",
            "205 novelty 3\n",
            "3\n",
            "206 informativeness 3\n",
            "3\n",
            "206 novelty 3\n",
            "3\n",
            "207 informativeness 3\n",
            "3\n",
            "207 novelty 3\n",
            "3\n",
            "208 informativeness 3\n",
            "3\n",
            "208 novelty 3\n",
            "3\n",
            "209 informativeness 3\n",
            "3\n",
            "209 novelty 3\n",
            "4\n",
            "210 informativeness 4\n",
            "2\n",
            "210 novelty 2\n",
            "4\n",
            "211 informativeness 4\n",
            "3\n",
            "211 novelty 3\n",
            "4\n",
            "212 informativeness 4\n",
            "2\n",
            "212 novelty 2\n",
            "3\n",
            "213 informativeness 3\n",
            "2\n",
            "213 novelty 2\n",
            "3\n",
            "214 informativeness 3\n",
            "2\n",
            "214 novelty 2\n",
            "3\n",
            "215 informativeness 3\n",
            "2\n",
            "215 novelty 2\n",
            "4\n",
            "216 informativeness 4\n",
            "2\n",
            "216 novelty 2\n",
            "3\n",
            "217 informativeness 3\n",
            "3\n",
            "217 novelty 3\n",
            "3\n",
            "218 informativeness 3\n",
            "3\n",
            "218 novelty 3\n",
            "3\n",
            "219 informativeness 3\n",
            "3\n",
            "219 novelty 3\n",
            "4\n",
            "220 informativeness 4\n",
            "3\n",
            "220 novelty 3\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: 'I'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 162\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Fluency (1-3): \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m geval_result[paperId][dimension]:\n\u001b[1;32m    161\u001b[0m                 geval_result[paperId][dimension]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeval_result[paperId][dimension]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 162\u001b[0m             score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgeval_result\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpaperId\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m             geval_avg_scores[dimension] \u001b[38;5;241m=\u001b[39m geval_avg_scores[dimension] \u001b[38;5;241m+\u001b[39m score\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m geval_avg_scores:\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'I'"
          ]
        }
      ],
      "source": [
        "error_list=[]\n",
        "i = 0\n",
        "openai.api_key = \"0de53d4ada864cd18e3771d16551aee1\"\n",
        "openai.api_base = \"https://biocodeeval-openai.openai.azure.com/\"\n",
        "openai.api_type = 'azure'\n",
        "openai.api_version = '2023-05-15' # this may change in the future\n",
        "key_bundles = [\n",
        "    ('0de53d4ada864cd18e3771d16551aee1', \"https://biocodeeval-openai.openai.azure.com/\"),\n",
        "    ('0de53d4ada864cd18e3771d16551aee1', \"https://biocodeeval-openai.openai.azure.com/\"),\n",
        "    ('0de53d4ada864cd18e3771d16551aee1', \"https://biocodeeval-openai.openai.azure.com/\")\n",
        "]\n",
        "\n",
        "\n",
        "def run_openai(prompt,key_bundles,i,indice):\n",
        "    my_dict = {}\n",
        "    my_dict[\"role\"] = \"user\"\n",
        "    my_dict[\"content\"] = prompt\n",
        "    l = []\n",
        "    l.append(my_dict)\n",
        "    result = \"\"\n",
        "    try:\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "        result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "        # print(indice+\"\\t\"+result+\"\\n\")\n",
        "        return result\n",
        "    except openai.error.Timeout:\n",
        "        i = i+1\n",
        "        print(\"Timeout\",indice)\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "            result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "            # print(indice+\"\\t\"+result+\"\\n\")\n",
        "            return result\n",
        "        except openai.error.Timeout:\n",
        "            i = i+1\n",
        "            print(\"Timeout\",indice)\n",
        "            key_bundle = key_bundles[i%3]\n",
        "            openai.api_key, openai.api_base = key_bundle\n",
        "            try:\n",
        "                response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "                result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "                # print(indice+\"\\t\"+result+\"\\n\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {str(e)}\")\n",
        "                error_list.append(i)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            error_list.append(i)\n",
        "        #print(result)\n",
        "    except openai.error.InvalidRequestError:\n",
        "        print(\"InvalidRequestError\",indice)\n",
        "        error_list.append(i)\n",
        "        #print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        error_list.append(i)\n",
        "    return result\n",
        "\n",
        "# G-EVAL \n",
        "def construct_prompt_g_eval(source,output,dimension):\n",
        "\n",
        "    Name = \"\"\n",
        "    Description = \"\"\n",
        "    Instruction = \"Evaluation Steps:\\n\"\n",
        "    dimensions_single_inputs = [\"novelty\",\"informativeness\"]\n",
        "\n",
        "    if dimension == \"coherence\":\n",
        "        Name = \"Coherence\"\n",
        "        Description = \"Coherence (1-5) - the collective quality of all sentences. We align this dimension with the DUC quality question of structure and coherence whereby \\\"the title should be well-structured and well-organized. The title should not just be a heap of related information, but should build from sentence to a coherent body of information about a topic.\\\"\\n\"\n",
        "        Instruction = Instruction + \"1. Read the science paper abstract carefully and identify the main topic and key points.\" + \"\\n\"\n",
        "        Instruction = Instruction + \"2. Read the title and compare it to the science paper abstract. Check if the title covers the main topic and key points of the paper abstract, and if it presents them in a clear and logical order.\" + \"\\n\"\n",
        "        Instruction = Instruction + \"3. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\" + \"\\n\"\n",
        "    elif dimension == \"consistency\":\n",
        "        Name = \"Consistency\"\n",
        "        Description = \"Consistency (1-5) - the factual alignment between the title and the science paper abstract. A factually consistent title contains only statements that are entailed by the source document. Annotators were also asked to penalize titles that contained hallucinated facts. \\n\"\n",
        "        Instruction = Instruction + \"1. Read the science paper abstract carefully and identify the main facts and details it presents.\" + \"\\n\"\n",
        "        Instruction = Instruction + \"2. Read the title and compare it to the source abstract. Check if the title contains any factual errors that are not supported by the abstract.\" + \"\\n\"\n",
        "        Instruction = Instruction + \"3. Assign a score for consistency on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\" + \"\\n\"\n",
        "    elif dimension == \"fluency\":\n",
        "        Name = \"Fluency (1-3)\"\n",
        "        Description = \"Fluency (1-3): the quality of the title in terms of grammar, spelling, punctuation, word choice, and sentence structure.\\n\"\n",
        "        Description = Description + \"- 1: Poor. The title has many errors that make it hard to understand or sound unnatural.\\n\"\n",
        "        Description = Description + \"- 2: Fair. The title has some errors that affect the clarity or smoothness of the text, but the main points are still comprehensible.\\n\"\n",
        "        Description = Description + \"- 3: Good. The title has few or no errors and is easy to read and follow.\\n\"\n",
        "        Instruction = \"\"\n",
        "    elif dimension == \"relevance\":\n",
        "        Name = \"Relevance\"\n",
        "        Description = \"Relevance (1-5) - selection of important content from the source. The title should include only important information from the source document. Annotators were instructed to penalize titles which contained redundancies and excess information.\\n\"\n",
        "        Instruction = Instruction + \"1. Read the title and the source document carefully.\" + \"\\n\"\n",
        "        Instruction = Instruction + \"2. Compare the title to the source document and identify the main points of the science paper.\" + \"\\n\"\n",
        "        Instruction = Instruction + \"3. Assess how well the title covers the main points of the article, and how much irrelevant or redundant information it contains.\" + \"\\n\"\n",
        "        Instruction = Instruction + \"4. Assign a relevance score from 1 to 5.\" + \"\\n\"\n",
        "    \n",
        "    elif dimension == \"informativeness\":\n",
        "        Name = \"Informativeness\"\n",
        "        Description = \"Informativeness(1-5) - the amount of information, including concepts, key points and findings, from the title. Annotators were instructed to penalize titles which contained under-explored concepts or redundancies and excess information.\\n\"\n",
        "        Instruction = Instruction + \"1. Read the title and the source title carefully.\" + \"\\n\"\n",
        "        Instruction = Instruction + \"2. Check if the title effectively communicate the main topic, key points, and significant findings or conclusions. Assess if the information provided is comprehensive, accurate, and complete.\" + \"\\n\"\n",
        "        Instruction = Instruction + \"3. A good informative title (scored 4 or 5) should convey enough amount of conpcets and key points in a progressive manner, while the relatively poorer ones have vague descriptions and under-explored ideas(scored 1 or 2).\" + \"\\n\"\n",
        "        Instruction = Instruction + \"4. Assign a score for informativeness on a scale of 1 to 5, to make the reuslts more clearly distributed, please avoid giving score 4\" + \"\\n\"\n",
        "        \n",
        "    elif dimension == \"novelty\":\n",
        "        Name = \"Novelty (1-3)\"\n",
        "        Description = \"Novelty (1-3): the uniqueness and originality of the title in terms of concept, perspective, and creativity. \\n\"\n",
        "        Description = Description + \"- 1: Poor. The title lacks originality and uniqueness, and it closely resembles existing or common titles. \\n\"\n",
        "        Description = Description + \"- 2: Fair. Thetitle shows some degree of uniqueness and creativity, but it still has elements that are common or predictable. \\n\"\n",
        "        Description = Description + \"- 3: Good. The title is highly original and unique, offering a fresh and creative perspective that stands out from common titles.\\n\"\n",
        "        Instruction = \"Assign a score for novelty on a scale of 1 to 3\"\n",
        "\n",
        "    prompt_str = \"\"\n",
        "    prompt_str = prompt_str + \"You will be given one title written for a science paper.\\n\"\n",
        "    prompt_str = prompt_str + \"Your task is to rate the output on one metric.\\n\"\n",
        "    prompt_str = prompt_str + \"Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\\n\"\n",
        "    prompt_str = prompt_str + \"Evaluation Criteria:\\n\"\n",
        "    prompt_str = prompt_str + Description\n",
        "    prompt_str = prompt_str + Instruction\n",
        "    if dimension not in dimensions_single_inputs:\n",
        "        prompt_str = prompt_str + \"Main topic:\\n\"\n",
        "        prompt_str = prompt_str + source + \"\\n\"\n",
        "    prompt_str = prompt_str + \"title:\\n\"\n",
        "    prompt_str = prompt_str + output + \"\\n\"\n",
        "    prompt_str = prompt_str + \"Evaluation Form (scores ONLY):\\n\"\n",
        "    prompt_str = prompt_str + \"- \"+Name+\":\"\n",
        "\n",
        "    return prompt_str\n",
        "\n",
        "dimensions = [\"novelty\"]\n",
        "geval_result = {}\n",
        "\n",
        "\n",
        "i = 0\n",
        "for j,id in enumerate(author2interests):\n",
        "    geval_result[id] = {}\n",
        "    if True:\n",
        "        if id in authors_sampled and id in id2interest_pred:\n",
        "            for dimension in dimensions:\n",
        "                prompt = construct_prompt_g_eval(\" \".join(author2interests[id]),\" \".join(id2interest_pred[id]),dimension)\n",
        "                # print(prompt)\n",
        "                \n",
        "                # prompt = construct_prompt_g_eval(papers_sampled[id][\"title\"],papers_sampled[id][\"abstract\"],dimension)\n",
        "                # break\n",
        "                result = run_openai(prompt,key_bundles,i,i)\n",
        "                print(result)\n",
        "                print(str(j),str(dimension),str(result))\n",
        "                geval_result[id][dimension] = result\n",
        "                i = i + 1\n",
        "        # break\n",
        "        \n",
        "geval_avg_scores = {\"informativeness\":0,\"novelty\":0}\n",
        "count = 0\n",
        "for paperId in geval_result:\n",
        "    if \"informativeness\" in geval_result[paperId]:\n",
        "        count = count + 1\n",
        "        for dimension in dimensions:\n",
        "            if \"1. Fluency (1-3): \" in geval_result[paperId][dimension]:\n",
        "                geval_result[paperId][dimension].replace(\"geval_result[paperId][dimension]\",\"\")\n",
        "            score = int(geval_result[paperId][dimension][0])\n",
        "            geval_avg_scores[dimension] = geval_avg_scores[dimension] + score\n",
        "\n",
        "for d in geval_avg_scores:\n",
        "    print(d+ \"\\t\" + str(geval_avg_scores[d]/count))\n",
        "count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1695905857665
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "informativeness\t3.3122171945701355\n",
            "novelty\t2.3936651583710407\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "geval_avg_scores = {\"informativeness\":0,\"novelty\":0}\n",
        "count = 0\n",
        "for paperId in geval_result:\n",
        "    if \"informativeness\" in geval_result[paperId]:\n",
        "        count = count + 1\n",
        "        for dimension in dimensions:\n",
        "            if \"1. Fluency (1-3): \" in geval_result[paperId][dimension]:\n",
        "                geval_result[paperId][dimension].replace(\"geval_result[paperId][dimension]\",\"\")\n",
        "            try:\n",
        "                score = int(geval_result[paperId][dimension][0])\n",
        "                geval_avg_scores[dimension] = geval_avg_scores[dimension] + score\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "for d in geval_avg_scores:\n",
        "    print(d+ \"\\t\" + str(geval_avg_scores[d]/count))\n",
        "count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "bioagent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
