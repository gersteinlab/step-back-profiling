{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697283351318
        }
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from heapq import nlargest\n",
        "import openai\n",
        "import torch\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "with open('../ScientificWritingDataset/authorJsonAndPaperJson/author_json.json', 'r',encoding='utf-8') as f:\n",
        "    authors_sampled = json.load(f)\n",
        "print(len(authors_sampled))\n",
        "\n",
        "with open('../ScientificWritingDataset/authorJsonAndPaperJson/paper_json.json', 'r',encoding='utf-8') as f:\n",
        "    papers_sampled = json.load(f)\n",
        "print(len(papers_sampled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1693556621525
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# sampled papers to 500 \n",
        "count = 0\n",
        "max_paper = 100\n",
        "author_paper_count = []\n",
        "paper_author_count = []\n",
        "papers_sampled = {}\n",
        "authors_sampled = {}\n",
        "for i in papers:\n",
        "    if count < 100:\n",
        "        flag = True\n",
        "        for author in papers[i][\"authors\"]:\n",
        "            if len(authors[author][\"papers\"])<5:\n",
        "                flag = False\n",
        "        if flag and len(papers[i][\"authors\"]) > 1:\n",
        "            paper_author_count.append(len(papers[i][\"authors\"]))\n",
        "            papers_sampled[i] = papers[i]\n",
        "            papers_sampled[i][\"author_history\"] = {}\n",
        "            \n",
        "            for author in papers[i][\"authors\"]:\n",
        "                papers_sampled[i][\"author_history\"][author] = {}\n",
        "                papers_sampled[i][\"author_history\"][author][\"authors_history_text\"] = [papers[i][\"abstract\"]]\n",
        "                papers_sampled[i][\"author_history\"][author][\"authors_history_dict\"] = []\n",
        "                paper_count_tmp = 0\n",
        "                for paper_tmp in authors[author][\"papers\"]:\n",
        "                    if paper_count_tmp < max_paper and paper_tmp[\"title\"] != papers[i][\"title\"]:\n",
        "                        papers_sampled[i][\"author_history\"][author][\"authors_history_text\"].append(\"Abstract: \"+paper_tmp[\"abstract\"]+\"\\nTitle: \"+paper_tmp[\"title\"])\n",
        "                        papers_sampled[i][\"author_history\"][author][\"authors_history_dict\"].append({\"Abstract\":paper_tmp[\"abstract\"],\"Title\":paper_tmp[\"title\"]})\n",
        "                        paper_count_tmp = paper_count_tmp + 1\n",
        "                author_paper_count.append(len(authors[author][\"papers\"]))\n",
        "                authors_sampled[author] = authors[author]\n",
        "            count = count + 1\n",
        "print(\"papers count after sampled: \",len(papers_sampled))\n",
        "print(\"authors count after sampled: \",len(authors_sampled))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697280372209
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"author to papers: \", min(author_paper_count),max(author_paper_count),sum(author_paper_count)/len(author_paper_count))\n",
        "print(\"paper to authors: \", min(paper_author_count),max(paper_author_count),sum(paper_author_count)/len(paper_author_count))\n",
        "\n",
        "for i in papers_sampled:\n",
        "    print(papers_sampled[i][\"title\"])\n",
        "    print(papers_sampled[i][\"author_history\"][\"1705375\"][\"authors_history_text\"])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697283474790
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import csv\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from heapq import nlargest\n",
        "import random\n",
        "import openai\n",
        "import time\n",
        "import torch\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "TOP_K = 20\n",
        "task_num = \"1\"\n",
        "i = 0\n",
        "error_list=[]\n",
        "openai.api_key = \"\"\n",
        "openai.api_base = \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"\n",
        "openai.api_type = 'azure'\n",
        "openai.api_version = '2023-05-15' # this may change in the future\n",
        "key_bundles = [\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\")\n",
        "]\n",
        "\n",
        "\n",
        "# Contriever part\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/contriever')\n",
        "model = AutoModel.from_pretrained('facebook/contriever')\n",
        "\n",
        "# Mean pooling\n",
        "def mean_pooling(token_embeddings, mask):\n",
        "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
        "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
        "    return sentence_embeddings\n",
        "\n",
        "\n",
        "def construct_prompt_for_user_profile(evidences,profile_type):\n",
        "    prompt_str = \"\"\n",
        "    if profile_type == \"topics\":\n",
        "        evidence_str = \"\"\n",
        "        prompt_str = \"Given the following scientific paper writing history, Use a few words to describe the topics that could represent user's interests:\\n\"\n",
        "        for index, evidence in enumerate(evidences):\n",
        "            evidence_str = \"History #\"+str(index) +\"\\nAbstract: \"+evidence[\"Abstract\"]+\"\\nTitle: \"+evidence[\"Title\"]\n",
        "        prompt_str = prompt_str + evidence_str +\"\\nTopics:\"\n",
        "    if profile_type == \"keywords\":\n",
        "        evidence_str = \"\"\n",
        "        prompt_str = \"Given the following scientific paper writing history, extract the top common keywords in the titles that may represent users' interests:\\n\"\t\n",
        "        for index, evidence in enumerate(evidences):\t\n",
        "            evidence_str = \"History #\"+str(index) +\"\\nAbstract: \"+evidence[\"Abstract\"]+\"\\nTitle: \"+evidence[\"Title\"]\n",
        "        prompt_str = prompt_str + evidence_str +\"\\nKeywords:\"\n",
        "    return prompt_str\n",
        "\n",
        "def run_openai(prompt,key_bundles,i):\n",
        "    my_dict = {}\n",
        "    my_dict[\"role\"] = \"user\"\n",
        "    my_dict[\"content\"] = prompt\n",
        "    l = []\n",
        "    l.append(my_dict)\n",
        "    result = \"\"\n",
        "    try:\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "        result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "        print(indice+\"\\t\"+result+\"\\n\")\n",
        "        return result\n",
        "    except openai.error.Timeout:\n",
        "        i = i+1\n",
        "        print(\"Timeout\",indice)\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "            result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "            print(indice+\"\\t\"+result+\"\\n\")\n",
        "            return result\n",
        "        except openai.error.Timeout:\n",
        "            i = i+1\n",
        "            print(\"Timeout\",indice)\n",
        "            key_bundle = key_bundles[i%3]\n",
        "            openai.api_key, openai.api_base = key_bundle\n",
        "            try:\n",
        "                response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "                result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "                print(indice+\"\\t\"+result+\"\\n\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {str(e)}\")\n",
        "                error_list.append(i)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            error_list.append(i)\n",
        "        #print(result)\n",
        "    except openai.error.InvalidRequestError:\n",
        "        print(\"InvalidRequestError\",indice)\n",
        "        error_list.append(i)\n",
        "        #print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        error_list.append(i)\n",
        "    return result\n",
        "authorDict = {}\n",
        "\n",
        "with open(\"naive_method_v3.0/author_profiling_\"+str(TOP_K)+\"_examples_.tsv\", \"wb\", buffering=0) as out_file:\n",
        "    for indice in papers_sampled:\n",
        "        for authorId in papers_sampled[indice][\"author_history\"]:\n",
        "            if authorId not in authorDict:\n",
        "                top_score_docs = random.sample(papers_sampled[indice][\"author_history\"][authorId][\"authors_history_dict\"], min(TOP_K,len(papers_sampled[indice][\"author_history\"][authorId][\"authors_history_dict\"])))\n",
        "                # build prompt with history and question \n",
        "                prompt = construct_prompt_for_user_profile(top_score_docs,\"keywords\")\n",
        "                keywords = run_openai(prompt,key_bundles,i)\n",
        "                # time.sleep(2)\n",
        "                i = i +1\n",
        "                prompt = construct_prompt_for_user_profile(top_score_docs,\"topics\")\n",
        "                topics = run_openai(prompt,key_bundles,i)\n",
        "                i = i +1\n",
        "                write_str = bytes(str(authorId)+\"\\t\"+keywords+\"\\t\"+topics+\"\\n\", 'utf-8')\n",
        "                out_file.write(write_str)\n",
        "                authorDict[authorId] = 1"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "bioagent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
