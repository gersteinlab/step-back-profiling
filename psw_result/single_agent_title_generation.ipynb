{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1697343269575
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "281\n",
            "107\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from heapq import nlargest\n",
        "import openai\n",
        "import torch\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "with open('data_set_v3.0/author_json.json', 'r',encoding='utf-8') as f:\n",
        "    authors_sampled = json.load(f)\n",
        "print(len(authors_sampled))\n",
        "\n",
        "with open('data_set_v3.0/paper_json.json', 'r',encoding='utf-8') as f:\n",
        "    papers_sampled = json.load(f)\n",
        "print(len(papers_sampled))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1697343707844
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_history = pd.read_csv('naive_method_v3.0/paper_to_author_cot_5_examples.tsv', sep='\\t', header=None, names=[\"paper_index\",\"author_index\",\"example_index\",\"result\",\"abstract\",\"title\"])\n",
        "user_keywords_topics = pd.read_csv('naive_method_v3.0/author_profiling_20_examples_.tsv', sep='\\t', header=None, names=[\"author_index\",\"keywords\",\"topics\"])\n",
        "\n",
        "id2authorTopics = {}\n",
        "id2authorInfo = {}\n",
        "id2ICLexamples = {}\n",
        "for i in range(len(user_keywords_topics[\"author_index\"])):\n",
        "    id2authorTopics[user_keywords_topics[\"author_index\"][i]] = {\"keywords\":user_keywords_topics[\"keywords\"][i],\"topics\":user_keywords_topics[\"topics\"][i]}\n",
        "\n",
        "for i in range(len(input_history[\"paper_index\"])):\n",
        "    paperId = input_history[\"paper_index\"][i]\n",
        "\n",
        "    authorId = input_history[\"author_index\"][i]\n",
        "    if paperId not in id2ICLexamples:\n",
        "        id2ICLexamples[paperId] = {}\n",
        "    if authorId not in id2ICLexamples[paperId]:\n",
        "        id2ICLexamples[paperId][authorId]=[]\n",
        "    id2ICLexamples[paperId][authorId].append({\"abstract\":input_history[\"abstract\"][i],\"title\":input_history[\"title\"][i],\"result\":input_history[\"result\"][i]})\n",
        "\n",
        "    if authorId not in id2authorInfo:\n",
        "        id2authorInfo[authorId]=[]\n",
        "    id2authorInfo[authorId].append({\"abstract\":input_history[\"abstract\"][i],\"title\":input_history[\"title\"][i],\"result\":input_history[\"result\"][i]})\n",
        "\n",
        "\n",
        "\n",
        "# Swap author ID\n",
        "import random\n",
        "authorList = [i for i in id2authorTopics]\n",
        "for paperId in id2ICLexamples:\n",
        "    # # Swap First Author \n",
        "    # oldAuhtorId = next(iter(id2ICLexamples[paperId]))\n",
        "    # Swap random author \n",
        "    oldAuhtorId =  random.choice([i for i in id2ICLexamples[paperId]])\n",
        "    newAuhtorId = oldAuhtorId\n",
        "    while newAuhtorId in id2ICLexamples[paperId]:\n",
        "        newAuhtorId = random.choice(authorList)\n",
        "    tempAuthorDict = {}\n",
        "    for i,authorId in enumerate(id2ICLexamples[paperId]):\n",
        "        if oldAuhtorId ==authorId:\n",
        "            tempAuthorDict[newAuhtorId] = id2authorInfo[newAuhtorId]\n",
        "        else:\n",
        "            tempAuthorDict[authorId] = id2authorInfo[authorId]\n",
        "    id2ICLexamples[paperId] = tempAuthorDict\n",
        "print([i for i in id2ICLexamples[\"130862d54894966552cb85d3ee6f739f885d4989\"]])\n",
        "print(id2ICLexamples[\"130862d54894966552cb85d3ee6f739f885d4989\"])\n",
        "\n",
        "len(id2authorTopics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697343334564
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "error_list=[]\n",
        "i = 0\n",
        "openai.api_key = \"\"\n",
        "openai.api_base = \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"\n",
        "openai.api_type = 'azure'\n",
        "openai.api_version = '2023-05-15' # this may change in the future\n",
        "key_bundles = [\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\")\n",
        "]\n",
        "\n",
        "\n",
        "    # prompt_construction v1.6\n",
        "def construct_prompt_cot_agg(author_dict,authorId,paperId):\n",
        "    prompt_str = \"\"\n",
        "    keywords = \"\"\n",
        "    if \"keywords\" in id2authorTopics[authorId]:\n",
        "        keywords = str(id2authorTopics[authorId][\"keywords\"])\n",
        "    topics = \"\"\n",
        "    if \"topics\" in id2authorTopics[authorId]:\n",
        "        topics = str(id2authorTopics[authorId][\"topics\"])\n",
        "    prompt_str = prompt_str + \"Assuming you are an expert researcher in these areas:\\n\"\n",
        "    prompt_str = prompt_str + \"Keywords:\" + keywords + \"\\nTopics: \"+topics+\"\\n\"\n",
        "    question = papers_sampled[paperId][\"abstract\"]\n",
        "\n",
        "    question_example = []\n",
        "    option1_example = []\n",
        "    option2_example = []\n",
        "    count = 0\n",
        "    for index,item in enumerate(author_dict):\n",
        "        question_example.append(\"Example #\"+str(index)+\"\\nAbstract: \"+item[\"abstract\"]+\"\\nStyle: \"+item[\"result\"]+\"\\nTitle: \"+item[\"title\"])\n",
        "\n",
        "    prompt_str = prompt_str + \"I give you some titles and paper abstracts that you've written. Please imitate your style of writing titles. Each example consists of an abstract, the corresponding title, and a description of the writing style and keywords for that title.\\n\"\n",
        "    prompt_str = prompt_str + \"\\n\".join(question_example) + \"\\n\"\n",
        "    prompt_str = prompt_str + \"Now you have written this abstract:\\n\"\n",
        "    prompt_str = prompt_str + \"Abstract:\" + question + \"\\n\"\n",
        "    prompt_str = prompt_str + \"Please write a title following your previous style and habits, and keep it clear and accurate:\\n\"\n",
        "    prompt_str = prompt_str + \"Title: \"\n",
        "\n",
        "    return prompt_str\n",
        "\n",
        "\n",
        "def run_openai(prompt,key_bundles,i,indice):\n",
        "    my_dict = {}\n",
        "    my_dict[\"role\"] = \"user\"\n",
        "    my_dict[\"content\"] = prompt\n",
        "    l = []\n",
        "    l.append(my_dict)\n",
        "    result = \"\"\n",
        "    try:\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "        result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "        # print(indice+\"\\t\"+result+\"\\n\")\n",
        "        return result\n",
        "    except openai.error.Timeout:\n",
        "        i = i+1\n",
        "        print(\"Timeout\",indice)\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "            result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "            # print(indice+\"\\t\"+result+\"\\n\")\n",
        "            return result\n",
        "        except openai.error.Timeout:\n",
        "            i = i+1\n",
        "            print(\"Timeout\",indice)\n",
        "            key_bundle = key_bundles[i%3]\n",
        "            openai.api_key, openai.api_base = key_bundle\n",
        "            try:\n",
        "                response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "                result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "                # print(indice+\"\\t\"+result+\"\\n\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {str(e)}\")\n",
        "                error_list.append(i)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            error_list.append(i)\n",
        "        #print(result)\n",
        "    except openai.error.InvalidRequestError:\n",
        "        print(\"InvalidRequestError\",indice)\n",
        "        error_list.append(i)\n",
        "        #print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        error_list.append(i)\n",
        "    return result\n",
        "\n",
        "with open(\"naive_method_v3.0/single_author_based_title_5_examples.tsv\", \"wb\", buffering=0) as out_file:\n",
        "    for indice,paperId in enumerate(id2ICLexamples):\n",
        "        for authorId in id2ICLexamples[paperId]:\n",
        "            prompt = construct_prompt_cot_agg(id2ICLexamples[paperId][authorId],authorId,paperId)\n",
        "            # print(prompt)\n",
        "            # break\n",
        "            result = run_openai(prompt,key_bundles,i,indice)\n",
        "            print(indice, result)\n",
        "            write_str = bytes(str(paperId)+\"\\t\"+str(authorId)+\"\\t\"+result+\"\\n\", 'utf-8')\n",
        "            out_file.write(write_str)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1693577453369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now you have written this abstract:\n",
            "Abstract:This book discusses how model-based approaches can improve the daily practice of software professionals. This is known as Model-Driven Software Engineering (MDSE) or, simply, Model-Driven Engineering (MDE). MDSE practices have proved to increase efficiency and effectiveness in software development, as demonstrated by various quantitative and qualitative studies. MDSE adoption in the software industry is foreseen to grow exponentially in the near future, e.g., due to the convergence of software development and business analysis. The aim of this book is to provide you with an agile and flexible tool to introduce you to the MDSE world, thus allowing you to quickly understand its basic principles and techniques and to choose the right set of MDSE instruments for your needs so that you can start to benefit from MDSE right away. The book is organized into two main parts. The first part discusses the foundations of MDSE in terms of basic concepts (i.e., models and transformations), driving principles, application scenarios and current standards, like the well-known MDA initiative proposed by OMG (Object Management Group) as well as the practices on how to integrate MDSE in existing development processes. The second part deals with the technical aspects of MDSE, spanning from the basics on when and how to build a domain-specific modeling language, to the description of Model-to-Text and Model-to-Model transformations, and the tools that support the management of MDSE projects. The book is targeted to a diverse set of readers, spanning: professionals, CTOs, CIOs, and team managers that need to have a bird's eye vision on the matter, so as to take the appropriate decisions when it comes to choosing the best development techniques for their company or team; software analysts, developers, or designers that expect to use MDSE for improving everyday work productivity, either by applying the basic modeling techniques and notations or by defining new domain-specific modeling languages and applying end-to-end MDSE practices in the software factory; and academic teachers and students to address undergrad and postgrad courses on MDSE. In addition to the contents of the book, more resources are provided on the book's website http://www.mdse-book.com/, including the examples presented in the book. Table of Contents: Introduction / MDSE Principles / MDSE Use Cases / Model-Driven Architecture (MDA) / Integration of MDSE in your Development Process / Modeling Languages at a Glance / Developing your Own Modeling Language / Model-to-Model Transformations / Model-to-Text Transformations / Managing Models / Summary\n",
            "Please write a title for this abstract:\n",
            "Title: \n"
          ]
        }
      ],
      "source": [
        "# Zero shot results \n",
        "error_list=[]\n",
        "i = 0\n",
        "openai.api_key = \"\"\n",
        "openai.api_base = \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"\n",
        "openai.api_type = 'azure'\n",
        "openai.api_version = '2023-05-15' # this may change in the future\n",
        "key_bundles = [\n",
        "    ('', \"https://biocodeeval-openai.openai.azure.com/\"),\n",
        "    ('', \"https://gersteinbiocodeeval-eastus2.openai.azure.com/\"),\n",
        "    ('', \"https://biocodeeval-openai.openai.azure.com/\")\n",
        "]\n",
        "\n",
        "    # prompt_construction v1.6\n",
        "def construct_prompt_cot_agg(author_dict,paperId):\n",
        "    prompt_str = \"\"\n",
        "    question = papers_sampled[paperId][\"abstract\"]\n",
        "\n",
        "    prompt_str = prompt_str + \"Now you have written this abstract:\\n\"\n",
        "    prompt_str = prompt_str + \"Abstract:\" + question + \"\\n\"\n",
        "    prompt_str = prompt_str + \"Please write a title for this abstract:\\n\"\n",
        "    prompt_str = prompt_str + \"Title: \"\n",
        "\n",
        "    return prompt_str\n",
        "\n",
        "\n",
        "def run_openai(prompt,key_bundles,i,indice):\n",
        "    my_dict = {}\n",
        "    my_dict[\"role\"] = \"user\"\n",
        "    my_dict[\"content\"] = prompt\n",
        "    l = []\n",
        "    l.append(my_dict)\n",
        "    result = \"\"\n",
        "    try:\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "        result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "        # print(indice+\"\\t\"+result+\"\\n\")\n",
        "        return result\n",
        "    except openai.error.Timeout:\n",
        "        i = i+1\n",
        "        print(\"Timeout\",indice)\n",
        "        key_bundle = key_bundles[i%3]\n",
        "        openai.api_key, openai.api_base = key_bundle\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "            result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "            # print(indice+\"\\t\"+result+\"\\n\")\n",
        "            return result\n",
        "        except openai.error.Timeout:\n",
        "            i = i+1\n",
        "            print(\"Timeout\",indice)\n",
        "            key_bundle = key_bundles[i%3]\n",
        "            openai.api_key, openai.api_base = key_bundle\n",
        "            try:\n",
        "                response = openai.ChatCompletion.create(engine=\"gpt-35-turbo\", messages=l, temperature=0.0,request_timeout=30)\n",
        "                result = response.choices[0].message[\"content\"].replace('\\n', ' ')\n",
        "                # print(indice+\"\\t\"+result+\"\\n\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {str(e)}\")\n",
        "                error_list.append(i)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            error_list.append(i)\n",
        "        #print(result)\n",
        "    except openai.error.InvalidRequestError:\n",
        "        print(\"InvalidRequestError\",indice)\n",
        "        error_list.append(i)\n",
        "        #print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        error_list.append(i)\n",
        "    return result\n",
        "\n",
        "id2result = {}\n",
        "with open(\"naive_method_v1.0/zero_shot_results.tsv\", \"wb\", buffering=0) as out_file:\n",
        "    for indice,paperId in enumerate(id2ICLexamples):\n",
        "        prompt = construct_prompt_cot_agg(id2ICLexamples[paperId],paperId)\n",
        "        print(prompt)\n",
        "        break\n",
        "        result = run_openai(prompt,key_bundles,i,indice)\n",
        "        print(indice, result)\n",
        "        id2result[paperId] = result\n",
        "        write_str = bytes(str(paperId)+\"\\t\"+result+\"\\n\", 'utf-8')\n",
        "        out_file.write(write_str)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1693577428293
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from rouge import Rouge\n",
        "import evaluate\n",
        "pred = []\n",
        "gold = []\n",
        "for i in id2result:\n",
        "    pred.append(id2result[i])\n",
        "    gold.append(papers_sampled[i][\"title\"])\n",
        "def postprocess_text_generation(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "def create_metric_rouge():\n",
        "    rouge_metric = evaluate.load('rouge')\n",
        "    def compute_metrics(decoded_preds, decoded_labels):\n",
        "        decoded_preds, decoded_labels = postprocess_text_generation(decoded_preds, decoded_labels)\n",
        "        result_rouge = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "        result = {\"rouge-1\" : result_rouge[\"rouge1\"], \"rouge-L\" : result_rouge[\"rougeL\"]}\n",
        "        return result\n",
        "    return compute_metrics\n",
        "metric = create_metric_rouge()\n",
        "print(metric(pred, gold))"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
